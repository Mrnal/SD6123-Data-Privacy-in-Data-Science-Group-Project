{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ny5N25GK5ugS",
        "Q9wQvw8kKuMS",
        "iDs3b9gE2hIM",
        "xgHp94xmKwoX",
        "_XsOGrUHGF2D",
        "jR8fxEdFnaKb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Privacy sensitive dataset - Description\n",
        "NIH Chest X-ray Sample dataset with ~5000 images randomly sampled from the main dataset.\n",
        "\n",
        "Link to dataset :\n",
        "https://www.kaggle.com/datasets/nih-chest-xrays/sample"
      ],
      "metadata": {
        "id": "GauA6AW2qus6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9YQUJO_-xMAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q 'flwr[simulation]' 'flwr-datasets[vision]'"
      ],
      "metadata": {
        "id": "MHQZRgl4vp8h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import DataLoader\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Metrics, Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg, FedProx, FedAdam\n",
        "from flwr.simulation import run_simulation, start_simulation\n",
        "from flwr.server.strategy import DifferentialPrivacyClientSideFixedClipping\n",
        "from flwr.client.mod import fixedclipping_mod\n",
        "\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import copy\n",
        "from flwr.common import ndarray_to_bytes, bytes_to_ndarray, Parameters\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
        "disable_progress_bar()"
      ],
      "metadata": {
        "id": "u1TBDG9IDAMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87fc963-49db-4cbe-e9e2-66c98ed26421"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda\n",
            "Flower 1.18.0 / PyTorch 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q opacus"
      ],
      "metadata": {
        "id": "8WjcsxFg0i2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27df2d51-e4ab-40f6-99da-094cab793a6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the large size of the dataset, the API key from https://www.kaggle.com/datasets/nih-chest-xrays/sample is downloaded and uploaded to Google Colab"
      ],
      "metadata": {
        "id": "8MMytUClrQ8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "NfXKRZ0wwrDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d7404ba9-110e-4ea8-9020-d315aa26e538"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa1fd949-80e1-4235-a405-5455026e7898\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa1fd949-80e1-4235-a405-5455026e7898\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (3).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (3).json': b'{\"username\":\"mrnalikamohanraja\",\"key\":\"5acf814f1036c9fbde03f088f279f820\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "pjT7PdaDwrfT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nih-chest-xrays/sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isT9f03lwrdD",
        "outputId": "9161f209-06bf-42e0-db85-c4232adabc5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/nih-chest-xrays/sample\n",
            "License(s): CC0-1.0\n",
            "User cancelled operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"sample.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"nih_chest_xray_sample\")"
      ],
      "metadata": {
        "id": "49_VlM9fwu-j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List some files\n",
        "os.listdir(\"nih_chest_xray_sample\")"
      ],
      "metadata": {
        "id": "NIfKLHLNxA_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d563ac68-9185-4a4c-dc58-a629bdbcae72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_labels.csv', 'sample']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('nih_chest_xray_sample/sample')\n"
      ],
      "metadata": {
        "id": "TVdNh0q_xA9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07112d8b-4e49-4e75-9fbc-ecdb8c73874c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_labels.csv', 'sample', 'images']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "9QILX8m0JvKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set base directory in Colab\n",
        "BASE_DIR = 'nih_chest_xray_sample'\n",
        "\n",
        "# Load the CSV file\n",
        "csv_path = os.path.join(BASE_DIR, 'sample_labels.csv')\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(df.shape)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uIezHNnxA4T",
        "outputId": "420c9f69-ae2e-4235-c987-69d19731a96e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5606, 11)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5606 entries, 0 to 5605\n",
            "Data columns (total 11 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Image Index                  5606 non-null   object \n",
            " 1   Finding Labels               5606 non-null   object \n",
            " 2   Follow-up #                  5606 non-null   int64  \n",
            " 3   Patient ID                   5606 non-null   int64  \n",
            " 4   Patient Age                  5606 non-null   object \n",
            " 5   Patient Gender               5606 non-null   object \n",
            " 6   View Position                5606 non-null   object \n",
            " 7   OriginalImageWidth           5606 non-null   int64  \n",
            " 8   OriginalImageHeight          5606 non-null   int64  \n",
            " 9   OriginalImagePixelSpacing_x  5606 non-null   float64\n",
            " 10  OriginalImagePixelSpacing_y  5606 non-null   float64\n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 481.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add full file path to each image\n",
        "df['file_path'] = df['Image Index'].apply(lambda x: os.path.join('nih_chest_xray_sample/sample/images', x))"
      ],
      "metadata": {
        "id": "mzQlYElJsef7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the categorical columns to numerical to analyse the correlation\n",
        "\n",
        "# Function to process 'Patient Age'\n",
        "def process_age(age):\n",
        "    numeric_age = ''.join(filter(str.isdigit, age))\n",
        "    if 'M' in age:\n",
        "        return int(numeric_age) / 12  # Convert months to years\n",
        "    elif 'D' in age:\n",
        "        return int(numeric_age) / 365  # Convert days to years\n",
        "    return int(numeric_age)\n",
        "\n",
        "df['Patient Age'] = df['Patient Age'].apply(process_age)\n",
        "df['Patient Age'] = df['Patient Age'].astype(int)"
      ],
      "metadata": {
        "id": "XS9_46e7tKNA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Patient Age'] = pd.to_numeric(df['Patient Age'], errors='coerce')\n",
        "df['Patient Gender'] = df['Patient Gender'].map({'M': 1, 'F': 0})\n",
        "df['View Position'] = LabelEncoder().fit_transform(df['View Position'])"
      ],
      "metadata": {
        "id": "NufARXZzttTq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n",
        "\n",
        "for pathology in pathology_list :\n",
        "    df[pathology] = df['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)\n",
        "\n",
        "df['No Findings'] = df['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)"
      ],
      "metadata": {
        "id": "V8L8eqj3utFi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYObXrqKtggR",
        "outputId": "c16041ee-1618-4673-cefc-c90f551ce699"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5606 entries, 0 to 5605\n",
            "Data columns (total 27 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Image Index                  5606 non-null   object \n",
            " 1   Finding Labels               5606 non-null   object \n",
            " 2   Follow-up #                  5606 non-null   int64  \n",
            " 3   Patient ID                   5606 non-null   int64  \n",
            " 4   Patient Age                  5606 non-null   int64  \n",
            " 5   Patient Gender               5606 non-null   int64  \n",
            " 6   View Position                5606 non-null   int64  \n",
            " 7   OriginalImageWidth           5606 non-null   int64  \n",
            " 8   OriginalImageHeight          5606 non-null   int64  \n",
            " 9   OriginalImagePixelSpacing_x  5606 non-null   float64\n",
            " 10  OriginalImagePixelSpacing_y  5606 non-null   float64\n",
            " 11  file_path                    5606 non-null   object \n",
            " 12  Cardiomegaly                 5606 non-null   int64  \n",
            " 13  Emphysema                    5606 non-null   int64  \n",
            " 14  Effusion                     5606 non-null   int64  \n",
            " 15  Hernia                       5606 non-null   int64  \n",
            " 16  Nodule                       5606 non-null   int64  \n",
            " 17  Pneumothorax                 5606 non-null   int64  \n",
            " 18  Atelectasis                  5606 non-null   int64  \n",
            " 19  Pleural_Thickening           5606 non-null   int64  \n",
            " 20  Mass                         5606 non-null   int64  \n",
            " 21  Edema                        5606 non-null   int64  \n",
            " 22  Consolidation                5606 non-null   int64  \n",
            " 23  Infiltration                 5606 non-null   int64  \n",
            " 24  Fibrosis                     5606 non-null   int64  \n",
            " 25  Pneumonia                    5606 non-null   int64  \n",
            " 26  No Findings                  5606 non-null   int64  \n",
            "dtypes: float64(2), int64(22), object(3)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = df[['Follow-up #','Patient ID', 'Patient Age', 'Patient Gender','View Position','OriginalImageWidth', 'OriginalImageHeight','OriginalImagePixelSpacing_x','OriginalImagePixelSpacing_y','No Findings']]\n",
        "corr_matrix = dataframe.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "Wea3Z0-QuH8S",
        "outputId": "af87d37a-a6dc-43c3-bb4e-900e512491a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can be seen that the 'No Findings' column does not have much dependency on the other columns"
      ],
      "metadata": {
        "id": "miS7yhF7v7Hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into Train and Test sets"
      ],
      "metadata": {
        "id": "UMt6LEL8J97q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "path = \"/content/nih_chest_xray_sample/sample/sample/images\"\n",
        "\n",
        "train_df = df.iloc[:int(len(df) * 0.8)]\n",
        "test_df = df.iloc[int(len(df) * 0.8):]\n",
        "\n",
        "test_df.reset_index(inplace=True)\n",
        "test_df.drop(columns=[\"index\"], inplace=True)\n",
        "\n",
        "train_paths = train_df[\"file_path\"].tolist()\n",
        "test_paths = test_df[\"file_path\"].tolist()\n",
        "\n",
        "print(\"Train Paths: \", len(train_paths))\n",
        "print(\"Test Paths: \", len(test_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtBaVqmLymv9",
        "outputId": "fe2af398-42d5-49c8-8e97-c247daa25bbe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Paths:  4484\n",
            "Test Paths:  1122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-75796174286e>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df.drop(columns=[\"index\"], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "destination_dir1 = \"./nih_images/train/\"\n",
        "destination_dir2 = \"./nih_images/test/\"\n",
        "\n",
        "for train_path in train_paths:\n",
        "  try:\n",
        "      # Ensure the destination directory exists\n",
        "      os.makedirs(destination_dir1, exist_ok=True)\n",
        "\n",
        "      # Copy the file\n",
        "      shutil.copy(train_path, destination_dir1)\n",
        "  except FileNotFoundError:\n",
        "        print(f\"Error: Source file not found: {train_path}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "print(f\"Image copied successfully to {destination_dir1}\")\n",
        "\n",
        "for test_path in test_paths:\n",
        "  try:\n",
        "      # Ensure the destination directory exists\n",
        "      os.makedirs(destination_dir2, exist_ok=True)\n",
        "\n",
        "      # Copy the file\n",
        "      shutil.copy(test_path, destination_dir2)\n",
        "  except FileNotFoundError:\n",
        "        print(f\"Error: Source file not found: {test_path}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "print(f\"Image copied successfully to {destination_dir2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZNHtrHA4Mbm",
        "outputId": "18307d6b-9a85-4aff-c3e7-6b54673abcd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image copied successfully to ./nih_images/train/\n",
            "Image copied successfully to ./nih_images/test/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class CXRDataset(Dataset):\n",
        "    def __init__(self, data, img_dir, transform=None):\n",
        "        self.data = data\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_file = self.img_dir + self.data.iloc[:,0][idx]\n",
        "        img = Image.open(img_file).convert('RGB')\n",
        "        label = np.array(self.data.iloc[:,-1].iloc[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "h3qza0Wp6fDx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading image data to the datasets"
      ],
      "metadata": {
        "id": "Dsa96YARJpwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "import torch\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLIENTS = 5\n",
        "\n",
        "def load_datasets(partition_id):\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize((224, 224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    trainset = CXRDataset(train_df, \"./nih_images/train/\", transform=transform)\n",
        "    testset = CXRDataset(test_df, \"./nih_images/test/\", transform=transform)\n",
        "\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    diff = len(trainset) - partition_size * NUM_CLIENTS\n",
        "\n",
        "    if diff  == 0:\n",
        "      lengths = [partition_size] * NUM_CLIENTS\n",
        "    else:\n",
        "      lengths = [partition_size] * (NUM_CLIENTS - 1)\n",
        "      lengths.append(partition_size + diff)\n",
        "\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    trainloader = []\n",
        "    valloader = []\n",
        "\n",
        "    for ds in datasets:\n",
        "      val_len = len(ds) // 10\n",
        "      train_len = len(ds) - val_len\n",
        "      lens = [train_len, val_len]\n",
        "\n",
        "      ds_train, ds_val =  random_split(ds, lens, torch.Generator().manual_seed(42))\n",
        "      trainloader.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "      valloader.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    if partition_id == -1: # for whole dataset (no clients - centralized model)\n",
        "      trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "      testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "      return trainloader, testloader\n",
        "\n",
        "    return trainloader[partition_id], valloader[partition_id], testloader"
      ],
      "metadata": {
        "id": "yoJhwm_7yBo6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model"
      ],
      "metadata": {
        "id": "kckJwe3lKBZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NetNIH(nn.Module):\n",
        "    def __init__(self, num_classes=1):  # num_classes = 1 for binary\n",
        "        super(NetNIH, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.LeakyReLU(0.01)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.LeakyReLU(0.01)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.relu3 = nn.LeakyReLU(0.01)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.relu4 = nn.LeakyReLU(0.01)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Calculate the flattened size based on the number of filters and the final feature map size\n",
        "        # For a 224x224 input, after 4 pooling layers (each reducing size by 2), the feature map size is 224/16 = 14 hence stop\n",
        "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
        "        self.relu5 = nn.LeakyReLU(0.01)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.relu6 = nn.LeakyReLU(0.01)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc_out = nn.Linear(128, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid() if num_classes == 1 else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3(self.conv3(x)))\n",
        "        x = self.pool4(self.relu4(self.conv4(x)))\n",
        "        x = x.view(-1, 256 * 14 * 14)\n",
        "        x = self.dropout1(self.relu5(self.fc1(x)))\n",
        "        x = self.dropout2(self.relu6(self.fc2(x)))\n",
        "        x = self.fc_out(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PlFQz01u8Qxy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gpu_memory_usage():\n",
        "    #Returns GPU memory usage in MB if CUDA is available, otherwise returns None\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated(0) / (1024 * 1024)\n",
        "        reserved = torch.cuda.memory_reserved(0) / (1024 * 1024)\n",
        "        return f\"Allocated: {allocated:.2f} MB, Reserved: {reserved:.2f} MB\"\n",
        "    return \"CUDA not available\""
      ],
      "metadata": {
        "id": "3JFpX6AI8mNB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NO59s5twscSx"
      },
      "outputs": [],
      "source": [
        "# Defining train and test functions\n",
        "def train(net, trainloader, epochs, strategy=None, global_params=None, config=None):\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    net.train()\n",
        "    total_train_start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        all_labels = []\n",
        "        all_predictions = []\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE).float().unsqueeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            if strategy == \"fed_prox\":\n",
        "              proximal_term = 0.0\n",
        "              for local_weights, global_weights in zip(net.parameters(), global_params):\n",
        "                  proximal_term += (local_weights - global_weights).norm(2)\n",
        "              loss += (config[\"proximal_mu\"] / 2) * proximal_term\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() * images.size(0)\n",
        "            total += labels.size(0)\n",
        "            predicted = (outputs.data > 0.45).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "            all_predictions.extend(predicted.cpu().numpy().flatten().tolist())\n",
        "\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        # Calculate precision, recall, and F1-score\n",
        "        precision = precision_score(all_labels, all_predictions, zero_division=1)\n",
        "        recall = recall_score(all_labels, all_predictions)\n",
        "        f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time = epoch_end_time - epoch_start_time\n",
        "        print(f\"Epoch: {epoch+1}/{epochs}, train loss {epoch_loss:.4f}, accuracy {epoch_acc:.4f}, precision {precision:.4f}, recall {recall:.4f}, f1-score {f1:.4f}, epoch time: {epoch_time:.4f} s, GPU Memory: {get_gpu_memory_usage()}\")\n",
        "\n",
        "    total_train_end_time = time.time()\n",
        "    total_training_time = total_train_end_time - total_train_start_time\n",
        "    print(f\"Total Training Time: {total_training_time:.4f} seconds\")\n",
        "\n",
        "def test(net, valloader):\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE).float().unsqueeze(1)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item() * images.size(0)\n",
        "            predicted = (outputs.data > 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "            all_predictions.extend(predicted.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    precision = precision_score(all_labels, all_predictions,zero_division=1)\n",
        "    recall = recall_score(all_labels, all_predictions)\n",
        "    f1 = f1_score(all_labels, all_predictions)\n",
        "    return loss / len(valloader.dataset), accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Centralized Learning Model"
      ],
      "metadata": {
        "id": "ny5N25GK5ugS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader, testloader = load_datasets(partition_id=-1)\n",
        "net = NetNIH().to(DEVICE)\n",
        "\n",
        "print(\"Using Device:\", DEVICE)\n",
        "\n",
        "train(net, trainloader, 10)"
      ],
      "metadata": {
        "id": "Wn2-ovSfgvDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6628f76e-f3e0-4cfa-bb17-8cc1f192b2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Epoch: 1/10, train loss 0.6816, accuracy 0.5698, precision 0.5669, recall 0.9146, f1-score 0.7000, epoch time: 122.0616 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 2/10, train loss 0.6696, accuracy 0.5868, precision 0.5840, recall 0.8581, f1-score 0.6950, epoch time: 104.8816 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 3/10, train loss 0.6600, accuracy 0.5986, precision 0.5950, recall 0.8402, f1-score 0.6967, epoch time: 104.0252 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 4/10, train loss 0.6598, accuracy 0.5972, precision 0.5953, recall 0.8301, f1-score 0.6934, epoch time: 103.3503 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 5/10, train loss 0.6604, accuracy 0.6030, precision 0.5960, recall 0.8577, f1-score 0.7033, epoch time: 115.8446 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 6/10, train loss 0.6548, accuracy 0.6166, precision 0.6104, recall 0.8329, f1-score 0.7045, epoch time: 116.4678 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 7/10, train loss 0.6532, accuracy 0.6204, precision 0.6134, recall 0.8333, f1-score 0.7067, epoch time: 129.4782 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 8/10, train loss 0.6514, accuracy 0.6180, precision 0.6114, recall 0.8333, f1-score 0.7053, epoch time: 131.4352 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 9/10, train loss 0.6538, accuracy 0.6222, precision 0.6145, recall 0.8354, f1-score 0.7081, epoch time: 124.3759 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Epoch: 10/10, train loss 0.6492, accuracy 0.6256, precision 0.6183, recall 0.8297, f1-score 0.7086, epoch time: 108.1100 s, GPU Memory: Allocated: 417.63 MB, Reserved: 2132.00 MB\n",
            "Total Training Time: 1160.0358 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, precision, recall, f1 = test(net, testloader)\n",
        "print(f\"Test loss {loss}, accuracy {accuracy}, precision {precision}, recall {recall}, f1 {f1}\")"
      ],
      "metadata": {
        "id": "YIUGpukPMJMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b747a4-6654-428c-d474-f8cbc5210f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss 0.639896470488924, accuracy 0.6452762923351159, precision 0.6703296703296703, recall 0.6267123287671232, f1 0.647787610619469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing the communication overhead\n",
        "def estimate_centralized_data_size(data_dir):\n",
        "    \"\"\"Estimates the total size of a dataset directory in bytes.\"\"\"\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(data_dir):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            try:\n",
        "                total_size += os.path.getsize(fp)\n",
        "            except OSError as e:\n",
        "                print(f\"Error accessing file: {fp} - {e}\")\n",
        "    return total_size\n",
        "\n",
        "train_data_directory = './nih_images/train'\n",
        "centralized_communication_bytes = estimate_centralized_data_size(train_data_directory)\n",
        "centralized_communication_mb = centralized_communication_bytes / (1024 * 1024)\n",
        "print(f\"Estimated communication overhead for centralized learning: {centralized_communication_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV1rKf_qCljZ",
        "outputId": "80a84814-4a08-4b27-b1c4-fc3240fdf7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated communication overhead for centralized learning: 1703.86 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decentalized Learning Models\n",
        " 1. FedAvg\n",
        " 2. FedProx and\n",
        " 3. FedAdams"
      ],
      "metadata": {
        "id": "CaYaB3htJRzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def run_membership_inference_attack(model, train_loader, test_loader):\n",
        "    \"\"\"Evaluate privacy risk using a simple Membership Inference Attack (MIA).\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained global model.\n",
        "        train_loader (DataLoader): Loader for member (training) data.\n",
        "        test_loader (DataLoader): Loader for non-member (testing) data.\n",
        "\n",
        "    Returns:\n",
        "        float: AUC score indicating attack success (higher = worse privacy).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    train_confidences, test_confidences = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Collect confidence scores from the train set (members)\n",
        "        for x_img, y in train_loader:\n",
        "            x_img = x_img.to(DEVICE)\n",
        "            output = model(x_img)\n",
        "            confidence = torch.sigmoid(output).squeeze().cpu().numpy()\n",
        "            train_confidences.extend(confidence)\n",
        "\n",
        "        # Collect confidence scores from the test set (non-members)\n",
        "        for x_img, y in test_loader:\n",
        "            x_img = x_img.to(DEVICE)\n",
        "            output = model(x_img)\n",
        "            confidence = torch.sigmoid(output).squeeze().cpu().numpy()\n",
        "            test_confidences.extend(confidence)\n",
        "\n",
        "    # Labels: 1 = member, 0 = non-member\n",
        "    labels = [1] * len(train_confidences) + [0] * len(test_confidences)\n",
        "    scores = list(train_confidences) + list(test_confidences)\n",
        "\n",
        "    # Compute MIA AUC\n",
        "    auc = roc_auc_score(labels, scores)\n",
        "    print(f\"[Privacy Risk] Membership Inference Attack AUC: {auc:.4f}\")\n",
        "\n",
        "    return auc\n",
        "\n",
        "def load_weights_into_model(model, npz_path):\n",
        "    # Load the saved weights\n",
        "    loaded = np.load(npz_path)\n",
        "    param_list = [loaded[key] for key in loaded.files]\n",
        "\n",
        "    # Convert to proper state_dict\n",
        "    params_dict = zip(model.state_dict().keys(), param_list)\n",
        "    new_state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
        "\n",
        "    model.load_state_dict(new_state_dict, strict=True)\n",
        "    print(f\"Loaded weights from {npz_path} into model successfully.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "YK42IpEjKSvJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. FedAvg"
      ],
      "metadata": {
        "id": "Q9wQvw8kKuMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to get parameters and set parameters\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "notIvoK_Om31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Client class for FedAvg\n",
        "class FAClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        fit_start_time = time.time()\n",
        "        train(self.net, self.trainloader, epochs=2) # train here.\n",
        "        fit_end_time = time.time()\n",
        "        fit_duration = fit_end_time - fit_start_time\n",
        "        print(f\"Client fit in {fit_duration:.2f} seconds.\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        eval_start_time = time.time()\n",
        "        loss, accuracy, precision, recall, f1  = test(self.net, self.valloader)\n",
        "        eval_end_time = time.time()\n",
        "        eval_duration = eval_end_time - eval_start_time\n",
        "        print(f\"Client eval in {eval_duration:.2f} seconds.\")\n",
        "        print(f\"precision {precision}, recall {recall}, f1 {f1}\")\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "AzFZfZCDOm1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Flower client representing a single organization\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = NetNIH().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "    return FAClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "FAclient = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "EaqUxaycOq70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "JAN-XkNHOxJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saves the final model and retrieves model parameters\n",
        "class SaveModelStrategy(flwr.server.strategy.FedAvg):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round,\n",
        "        results,\n",
        "        failures,\n",
        "    ):\n",
        "\n",
        "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            aggregated_ndarrays: list[np.ndarray] = flwr.common.parameters_to_ndarrays(\n",
        "                aggregated_parameters\n",
        "            )\n",
        "\n",
        "            print(f\"FedAvg - Saving round {server_round} aggregated_ndarrays...\")\n",
        "            np.savez(f\"FedAvg - round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
        "\n",
        "        return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "\n",
        "# Create strategy and pass into ServerApp\n",
        "def server_fn(context):\n",
        "    FAstrategy = SaveModelStrategy(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=1.0,  # Sample 100% of available clients for evaluation\n",
        "        min_fit_clients=5,  # Never sample less than 5 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=5,  # Wait until all 5 clients are available\n",
        "        evaluate_metrics_aggregation_fn=weighted_average, # metric aggregation function\n",
        "    )\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "    return ServerAppComponents(strategy=FAstrategy, config=config)\n",
        "\n",
        "\n",
        "FAserver = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "wxdnHIHkX5LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ],
      "metadata": {
        "id": "detyK9nUQLGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FL simulation\n",
        "run_simulation(\n",
        "    server_app=FAserver,\n",
        "    client_app=FAclient,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "id": "U2F6yuvhQM7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53512baa-58cb-45ef-c1af-4761b7ee2760",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=4505)\u001b[0m 2025-04-25 18:11:28.996588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=4505)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=4505)\u001b[0m E0000 00:00:1745604689.028449    4505 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=4505)\u001b[0m E0000 00:00:1745604689.038271    4505 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.7103, accuracy 0.5713, precision 0.5722, recall 0.9495, f1-score 0.7140, epoch time: 21.6298 s, GPU Memory: Allocated: 419.46 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6871, accuracy 0.5613, precision 0.5627, recall 0.9956, f1-score 0.7190, epoch time: 19.9284 s, GPU Memory: Allocated: 419.46 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 41.5589 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 41.56 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.7030, accuracy 0.5390, precision 0.5481, recall 0.9553, f1-score 0.6966, epoch time: 19.4051 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6878, accuracy 0.5539, precision 0.5539, recall 1.0000, f1-score 0.7129, epoch time: 19.7759 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 39.1817 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 39.18 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.7005, accuracy 0.5217, precision 0.5327, recall 0.8845, f1-score 0.6649, epoch time: 19.5242 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6911, accuracy 0.5366, precision 0.5366, recall 1.0000, f1-score 0.6984, epoch time: 19.8464 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 39.3713 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 39.37 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6935, accuracy 0.5390, precision 0.5421, recall 0.8935, f1-score 0.6748, epoch time: 19.5054 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6814, accuracy 0.5762, precision 0.5668, recall 0.8843, f1-score 0.6908, epoch time: 20.0081 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 39.5142 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 39.51 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6909, accuracy 0.5556, precision 0.5580, recall 0.9442, f1-score 0.7015, epoch time: 19.4451 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6921, accuracy 0.5531, precision 0.5531, recall 1.0000, f1-score 0.7122, epoch time: 19.9522 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 39.3982 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 39.40 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAvg - Saving round 1 aggregated_ndarrays...\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 5.19 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.28 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 3.37 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.98 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 3.97 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6936, accuracy 0.5601, precision 0.5646, recall 0.9604, f1-score 0.7111, epoch time: 18.9288 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6933, accuracy 0.5564, precision 0.5629, recall 0.9538, f1-score 0.7080, epoch time: 19.7888 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.7183 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.72 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6924, accuracy 0.5527, precision 0.5535, recall 0.9955, f1-score 0.7114, epoch time: 18.7785 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6803, accuracy 0.5613, precision 0.5586, recall 0.9911, f1-score 0.7145, epoch time: 19.7181 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.4974 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.50 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6867, accuracy 0.5428, precision 0.5441, recall 0.9122, f1-score 0.6816, epoch time: 18.9372 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6792, accuracy 0.5428, precision 0.5457, recall 0.8822, f1-score 0.6743, epoch time: 19.9545 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.8926 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.89 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6853, accuracy 0.5428, precision 0.5426, recall 0.9282, f1-score 0.6849, epoch time: 18.8301 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6834, accuracy 0.5688, precision 0.5618, recall 0.8843, f1-score 0.6871, epoch time: 20.8877 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 39.7186 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 39.72 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6897, accuracy 0.5531, precision 0.5531, recall 1.0000, f1-score 0.7122, epoch time: 18.9959 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6924, accuracy 0.5469, precision 0.5541, recall 0.9263, f1-score 0.6934, epoch time: 19.8077 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.8044 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.80 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAvg - Saving round 2 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.93 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.5617977528089888, recall 1.0, f1 0.7194244604316546\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.53 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.5280898876404494, recall 1.0, f1 0.6911764705882353\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.91 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.550561797752809, recall 1.0, f1 0.7101449275362319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.85 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.5, recall 1.0, f1 0.6666666666666666\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6782, accuracy 0.5849, precision 0.5817, recall 0.9385, f1-score 0.7183, epoch time: 19.0222 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6789, accuracy 0.5960, precision 0.5961, recall 0.8791, f1-score 0.7105, epoch time: 19.8048 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.8280 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.7038, accuracy 0.5502, precision 0.5572, recall 0.9150, f1-score 0.6926, epoch time: 18.9900 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6758, accuracy 0.5551, precision 0.5580, recall 0.9463, f1-score 0.7021, epoch time: 19.5834 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.5743 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.57 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6856, accuracy 0.5527, precision 0.5525, recall 0.8753, f1-score 0.6774, epoch time: 19.1793 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6783, accuracy 0.5713, precision 0.5666, recall 0.8545, f1-score 0.6814, epoch time: 19.5107 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.6910 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.69 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6745, accuracy 0.5564, precision 0.5549, recall 0.8657, f1-score 0.6763, epoch time: 19.2139 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6628, accuracy 0.6270, precision 0.6135, recall 0.8194, f1-score 0.7017, epoch time: 19.4185 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.6333 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.63 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6865, accuracy 0.5630, precision 0.5607, recall 0.9688, f1-score 0.7103, epoch time: 19.2812 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6759, accuracy 0.5519, precision 0.5540, recall 0.9732, f1-score 0.7061, epoch time: 19.2498 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.5319 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.53 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAvg - Saving round 3 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6219512195121951, recall 0.9444444444444444, f1 0.75\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.24 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.5657894736842105, recall 0.86, f1 0.6825396825396826\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.27 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.5789473684210527, recall 0.9361702127659575, f1 0.7154471544715447\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.81 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6052631578947368, recall 0.9387755102040817, f1 0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.85 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.5584415584415584, recall 0.9555555555555556, f1 0.7049180327868853\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6702, accuracy 0.5787, precision 0.5782, recall 0.9341, f1-score 0.7143, epoch time: 19.7804 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6574, accuracy 0.6283, precision 0.6224, recall 0.8659, f1-score 0.7243, epoch time: 18.8517 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.6330 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.63 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6873, accuracy 0.5576, precision 0.5565, recall 0.9911, f1-score 0.7128, epoch time: 23.3627 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6719, accuracy 0.5849, precision 0.5862, recall 0.8523, f1-score 0.6946, epoch time: 18.8801 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 42.2436 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 42.24 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6838, accuracy 0.5551, precision 0.5527, recall 0.8961, f1-score 0.6837, epoch time: 19.7779 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6692, accuracy 0.6109, precision 0.6080, recall 0.7737, f1-score 0.6809, epoch time: 18.8269 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.6057 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.61 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6763, accuracy 0.5836, precision 0.5725, recall 0.8773, f1-score 0.6929, epoch time: 25.0038 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6712, accuracy 0.5886, precision 0.5769, recall 0.8681, f1-score 0.6932, epoch time: 19.8733 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 44.8778 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 44.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6752, accuracy 0.5815, precision 0.5758, recall 0.9241, f1-score 0.7095, epoch time: 18.9200 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6778, accuracy 0.5728, precision 0.5704, recall 0.9219, f1-score 0.7048, epoch time: 19.8350 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 38.7559 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 38.76 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAvg - Saving round 4 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 3.32 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.7192982456140351, recall 0.7592592592592593, f1 0.7387387387387387\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.22 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.5862068965517241, recall 0.68, f1 0.6296296296296297\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.16 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6666666666666666, recall 0.851063829787234, f1 0.7476635514018691\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.80 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6666666666666666, recall 0.7346938775510204, f1 0.6990291262135923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6724137931034483, recall 0.8666666666666667, f1 0.7572815533980582\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6643, accuracy 0.6022, precision 0.5952, recall 0.9209, f1-score 0.7230, epoch time: 22.5686 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6615, accuracy 0.6146, precision 0.6111, recall 0.8703, f1-score 0.7180, epoch time: 28.3002 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 50.8697 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 50.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6695, accuracy 0.5774, precision 0.5786, recall 0.8725, f1-score 0.6958, epoch time: 21.8223 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6639, accuracy 0.5923, precision 0.5952, recall 0.8255, f1-score 0.6917, epoch time: 21.1695 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 42.9927 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 42.99 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6771, accuracy 0.5675, precision 0.5640, recall 0.8545, f1-score 0.6795, epoch time: 21.2740 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6642, accuracy 0.6196, precision 0.6180, recall 0.7621, f1-score 0.6825, epoch time: 20.3188 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 41.5937 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 41.59 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6485, accuracy 0.6159, precision 0.6027, recall 0.8287, f1-score 0.6979, epoch time: 19.9670 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6392, accuracy 0.6332, precision 0.6189, recall 0.8194, f1-score 0.7052, epoch time: 19.9489 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 39.9167 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 39.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 1/2, train loss 0.6738, accuracy 0.5852, precision 0.5809, recall 0.8973, f1-score 0.7053, epoch time: 18.9390 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Epoch: 2/2, train loss 0.6850, accuracy 0.5667, precision 0.5716, recall 0.8638, f1-score 0.6880, epoch time: 21.2790 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Total Training Time: 40.2188 seconds\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client fit in 40.22 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAvg - Saving round 5 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.91 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.75, recall 0.7222222222222222, f1 0.7358490566037735\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6, recall 0.66, f1 0.6285714285714286\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.97 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6842105263157895, recall 0.8297872340425532, f1 0.75\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 2.45 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6491228070175439, recall 0.7551020408163265, f1 0.6981132075471698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 1109.76s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6933144755458713\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6898562476876078\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.683060664041212\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.6696814134028668\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.6572235459245547\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.45056179775280897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.5494382022471911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.6008988764044944),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.6590511860174783),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.6613233458177278)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4505)\u001b[0m precision 0.6610169491525424, recall 0.8666666666666667, f1 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimates the size of a PyTorch model in bytes\n",
        "def estimate_model_size(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.numel() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.numel() * buffer.element_size()\n",
        "    return param_size + buffer_size\n",
        "\n",
        "binary_model = NetNIH().to(DEVICE)\n",
        "model_size_bytes = estimate_model_size(binary_model)\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "num_rounds = 5\n",
        "num_clients = NUM_CLIENTS\n",
        "\n",
        "uplink_per_round_bytes = num_clients * model_size_bytes\n",
        "downlink_per_round_bytes = num_clients * model_size_bytes\n",
        "total_uplink_bytes = num_rounds * uplink_per_round_bytes\n",
        "total_downlink_bytes = num_rounds * downlink_per_round_bytes\n",
        "total_communication_bytes = total_uplink_bytes + total_downlink_bytes\n",
        "\n",
        "uplink_mb = total_uplink_bytes / (1024 * 1024)\n",
        "downlink_mb = total_downlink_bytes / (1024 * 1024)\n",
        "total_mb = total_communication_bytes / (1024 * 1024)\n",
        "\n",
        "print(\"\\n--- Federated Learning Communication Overhead Estimation ---\")\n",
        "print(f\"Estimated model size: {model_size_mb:.2f} MB\")\n",
        "print(f\"Number of clients: {num_clients}\")\n",
        "print(f\"Number of rounds: {num_rounds}\")\n",
        "print(f\"Estimated uplink communication (total): {uplink_mb:.2f} MB\")\n",
        "print(f\"Estimated downlink communication (total): {downlink_mb:.2f} MB\")\n",
        "print(f\"Estimated total communication: {total_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8ZKV_yxE8vY",
        "outputId": "c173af74-fad3-4a45-881c-65fd72e32d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Federated Learning Communication Overhead Estimation ---\n",
            "Estimated model size: 99.73 MB\n",
            "Number of clients: 5\n",
            "Number of rounds: 5\n",
            "Estimated uplink communication (total): 2493.37 MB\n",
            "Estimated downlink communication (total): 2493.37 MB\n",
            "Estimated total communication: 4986.73 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the full centralized train dataset\n",
        "central_trainset = CXRDataset(train_df, \"./nih_images/train/\", transform=transform)\n",
        "\n",
        "# Create the full test dataset\n",
        "central_testset = CXRDataset(test_df, \"./nih_images/test/\", transform=transform)\n",
        "\n",
        "# Now, DataLoaders\n",
        "central_train_loader = DataLoader(central_trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(central_testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Step 1: Rebuild model\n",
        "global_model = NetNIH().to(DEVICE)\n",
        "\n",
        "# Step 2: Load saved weights\n",
        "global_model = load_weights_into_model(global_model, \"/content/FedAvg - round-5-weights.npz\")\n",
        "\n",
        "# Step 3: Run MIA\n",
        "mia_auc = run_membership_inference_attack(global_model, central_train_loader, test_loader)\n",
        "print(f\"Membership Inference Attack AUC: {mia_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFd4O04CKP_a",
        "outputId": "fdae2669-7cec-4c10-c1b0-30ddd10b935f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/FedAvg - round-5-weights.npz into model successfully.\n",
            "[Privacy Risk] Membership Inference Attack AUC: 0.5190\n",
            "Membership Inference Attack AUC: 0.5190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. FedAvg-DP"
      ],
      "metadata": {
        "id": "iDs3b9gE2hIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to get parameters and set parameters\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "nebxG34L2hIP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Client class for FedAvg\n",
        "class FAClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        fit_start_time = time.time()\n",
        "        train(self.net, self.trainloader, epochs=2) # train here.\n",
        "        fit_end_time = time.time()\n",
        "        fit_duration = fit_end_time - fit_start_time\n",
        "        print(f\"Client fit in {fit_duration:.2f} seconds.\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        eval_start_time = time.time()\n",
        "        loss, accuracy, precision, recall, f1  = test(self.net, self.valloader)\n",
        "        eval_end_time = time.time()\n",
        "        eval_duration = eval_end_time - eval_start_time\n",
        "        print(f\"Client eval in {eval_duration:.2f} seconds.\")\n",
        "        print(f\"precision {precision}, recall {recall}, f1 {f1}\")\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "OY6VcJoe2hIP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Flower client representing a single organization\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = NetNIH().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "    return FAClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "FAclient = ClientApp(client_fn=client_fn, mods=[fixedclipping_mod])"
      ],
      "metadata": {
        "id": "EY2zqmdA2hIP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "5B59--fq2hIP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saves the final model and retrieves model parameters\n",
        "class SaveModelStrategy(flwr.server.strategy.FedAvg):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round,\n",
        "        results,\n",
        "        failures,\n",
        "    ):\n",
        "\n",
        "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            aggregated_ndarrays: list[np.ndarray] = flwr.common.parameters_to_ndarrays(\n",
        "                aggregated_parameters\n",
        "            )\n",
        "\n",
        "            print(f\"FedAvg-DP - Saving round {server_round} aggregated_ndarrays...\")\n",
        "            np.savez(f\"FedAvg-DP - round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
        "\n",
        "        return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "\n",
        "# Create strategy and pass into ServerApp\n",
        "def server_fn(context):\n",
        "    FAstrategy = SaveModelStrategy(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=1.0,  # Sample 100% of available clients for evaluation\n",
        "        min_fit_clients=5,  # Never sample less than 5 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=5,  # Wait until all 5 clients are available\n",
        "        evaluate_metrics_aggregation_fn=weighted_average, # metric aggregation function\n",
        "    )\n",
        "\n",
        "    # === Wrap in client-side DP fixed clipping ===\n",
        "    dp_strategy = DifferentialPrivacyClientSideFixedClipping(\n",
        "        FAstrategy,\n",
        "        noise_multiplier=1.0,    #  (tune as needed)\n",
        "        clipping_norm=1.0,       # C (tune as needed)\n",
        "        num_sampled_clients=5,   # number of clients per round\n",
        "    )\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "    return ServerAppComponents(strategy=dp_strategy, config=config)\n",
        "\n",
        "\n",
        "FAserver = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "KVkhHyI82hIP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ],
      "metadata": {
        "id": "CYGvXTul2hIP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FL simulation\n",
        "run_simulation(\n",
        "    server_app=FAserver,\n",
        "    client_app=FAclient,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f01131e-e4c9-4338-c765-807599365e02",
        "collapsed": true,
        "id": "WEYXeyer2hIQ"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=31363)\u001b[0m 2025-04-26 02:52:35.805172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=31363)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=31363)\u001b[0m E0000 00:00:1745635955.907488   31363 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=31363)\u001b[0m E0000 00:00:1745635955.917692   31363 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 0.7041, accuracy 0.5465, precision 0.5574, recall 0.9495, f1-score 0.7024, epoch time: 21.4641 s, GPU Memory: Allocated: 419.46 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 0.6805, accuracy 0.5626, precision 0.5634, recall 0.9956, f1-score 0.7196, epoch time: 20.2843 s, GPU Memory: Allocated: 419.46 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 41.7493 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 41.75 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 0.7064, accuracy 0.5415, precision 0.5501, recall 0.9463, f1-score 0.6957, epoch time: 21.3251 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 0.6947, accuracy 0.5551, precision 0.5550, recall 0.9933, f1-score 0.7121, epoch time: 20.0432 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 41.3713 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 41.37 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 0.7775, accuracy 0.5328, precision 0.5380, recall 0.9145, f1-score 0.6775, epoch time: 22.4340 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 0.6850, accuracy 0.5353, precision 0.5364, recall 0.9861, f1-score 0.6949, epoch time: 19.0320 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 41.4670 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 41.47 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 0.6921, accuracy 0.5638, precision 0.5602, recall 0.8611, f1-score 0.6788, epoch time: 20.8957 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 0.6740, accuracy 0.5874, precision 0.5855, recall 0.7847, f1-score 0.6706, epoch time: 18.8571 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 39.7535 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 39.75 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 0.7022, accuracy 0.5519, precision 0.5544, recall 0.9665, f1-score 0.7046, epoch time: 20.7383 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 0.6870, accuracy 0.5506, precision 0.5534, recall 0.9710, f1-score 0.7050, epoch time: 18.9481 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 39.6872 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 39.69 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAvg-DP - Saving round 1 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.6231884057971014, recall 0.7962962962962963, f1 0.6991869918699187\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.90 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5416666666666666, recall 0.78, f1 0.639344262295082\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.93 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5205479452054794, recall 0.8085106382978723, f1 0.6333333333333333\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.91 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5974025974025974, recall 0.9387755102040817, f1 0.7301587301587301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 2.73 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.49295774647887325, recall 0.7777777777777778, f1 0.603448275862069\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 50.1232, accuracy 0.4981, precision 0.5749, recall 0.4220, f1-score 0.4867, epoch time: 18.8921 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 54.8947, accuracy 0.4511, precision 0.5667, recall 0.1121, f1-score 0.1872, epoch time: 20.0266 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.9194 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.92 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 47.7725, accuracy 0.5217, precision 0.5639, recall 0.6018, f1-score 0.5823, epoch time: 18.8193 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 47.3358, accuracy 0.5266, precision 0.5476, recall 0.8367, f1-score 0.6619, epoch time: 19.7997 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.6197 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.62 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 46.5923, accuracy 0.5341, precision 0.5610, recall 0.6051, f1-score 0.5822, epoch time: 18.8520 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 51.0533, accuracy 0.4895, precision 0.5238, recall 0.5335, f1-score 0.5286, epoch time: 19.8162 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.6689 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.67 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 49.0706, accuracy 0.5093, precision 0.5435, recall 0.5208, f1-score 0.5319, epoch time: 18.8310 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 52.1685, accuracy 0.4783, precision 0.5364, recall 0.1875, f1-score 0.2779, epoch time: 19.7507 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.5825 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.58 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 51.4822, accuracy 0.4852, precision 0.5838, recall 0.2411, f1-score 0.3412, epoch time: 18.7841 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 54.4444, accuracy 0.4556, precision 0.5455, recall 0.0938, f1-score 0.1600, epoch time: 19.7332 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.5183 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.52 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAvg-DP - Saving round 2 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5568181818181818, recall 0.98, f1 0.7101449275362319\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 2.60 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5287356321839081, recall 0.9787234042553191, f1 0.6865671641791045\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.86 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5454545454545454, recall 0.9795918367346939, f1 0.7007299270072993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.86 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5, recall 0.9777777777777777, f1 0.6616541353383458\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 46.4684, accuracy 0.5353, precision 0.5738, recall 0.6835, f1-score 0.6239, epoch time: 19.0023 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 47.0880, accuracy 0.5291, precision 0.5712, recall 0.6615, f1-score 0.6130, epoch time: 19.6633 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.6664 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.67 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 47.4597, accuracy 0.5254, precision 0.5599, recall 0.6689, f1-score 0.6096, epoch time: 18.7892 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 49.0706, accuracy 0.5093, precision 0.5471, recall 0.6622, f1-score 0.5992, epoch time: 19.7505 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.5406 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.54 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 47.9554, accuracy 0.5204, precision 0.5434, recall 0.6651, f1-score 0.5981, epoch time: 18.8320 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 45.9727, accuracy 0.5403, precision 0.5572, recall 0.6975, f1-score 0.6195, epoch time: 19.6945 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.5273 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.53 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 49.0706, accuracy 0.5093, precision 0.5332, recall 0.6690, f1-score 0.5934, epoch time: 18.8410 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 47.4597, accuracy 0.5254, precision 0.5468, recall 0.6620, f1-score 0.5990, epoch time: 19.7901 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.6319 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.63 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 49.0123, accuracy 0.5099, precision 0.5466, recall 0.6674, f1-score 0.6010, epoch time: 19.7512 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 44.8148, accuracy 0.5519, precision 0.5758, recall 0.7210, f1-score 0.6402, epoch time: 20.0136 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 39.7672 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 39.77 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 5 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5568181818181818, recall 0.98, f1 0.7101449275362319\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 2.89 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5287356321839081, recall 0.9787234042553191, f1 0.6865671641791045\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.86 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5454545454545454, recall 0.9795918367346939, f1 0.7007299270072993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.95 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5, recall 0.9777777777777777, f1 0.6616541353383458\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 46.3445, accuracy 0.5366, precision 0.5732, recall 0.6967, f1-score 0.6290, epoch time: 19.8977 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 48.9467, accuracy 0.5105, precision 0.5556, recall 0.6593, f1-score 0.6030, epoch time: 19.2919 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 39.1906 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 39.19 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 46.3445, accuracy 0.5366, precision 0.5680, recall 0.6823, f1-score 0.6199, epoch time: 19.4453 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 47.8315, accuracy 0.5217, precision 0.5574, recall 0.6622, f1-score 0.6053, epoch time: 19.2947 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.7410 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.74 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 46.4684, accuracy 0.5353, precision 0.5569, recall 0.6559, f1-score 0.6023, epoch time: 19.5469 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 47.4597, accuracy 0.5254, precision 0.5463, recall 0.6813, f1-score 0.6064, epoch time: 19.2028 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.7505 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.75 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 48.6989, accuracy 0.5130, precision 0.5353, recall 0.6852, f1-score 0.6010, epoch time: 19.4468 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 48.3271, accuracy 0.5167, precision 0.5378, recall 0.6921, f1-score 0.6053, epoch time: 19.1894 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.6371 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.64 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 49.2593, accuracy 0.5074, precision 0.5453, recall 0.6585, f1-score 0.5966, epoch time: 19.4070 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 49.7575, accuracy 0.5012, precision 0.5470, recall 0.5714, f1-score 0.5590, epoch time: 19.4336 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.8415 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.84 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 4 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 2.04 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5568181818181818, recall 0.98, f1 0.7101449275362319\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 2.41 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5287356321839081, recall 0.9787234042553191, f1 0.6865671641791045\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5454545454545454, recall 0.9795918367346939, f1 0.7007299270072993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5, recall 0.9777777777777777, f1 0.6616541353383458\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 43.8662, accuracy 0.5613, precision 0.5947, recall 0.6967, f1-score 0.6417, epoch time: 19.8648 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 46.2206, accuracy 0.5378, precision 0.5756, recall 0.6857, f1-score 0.6259, epoch time: 19.0433 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.9090 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.91 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 46.7162, accuracy 0.5328, precision 0.5681, recall 0.6532, f1-score 0.6077, epoch time: 19.7606 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 48.0114, accuracy 0.5192, precision 0.5539, recall 0.6779, f1-score 0.6097, epoch time: 18.8452 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.6069 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.61 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m \u001b[92mINFO \u001b[0m:      fixedclipping_mod: parameters are clipped by value: 1.0000.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 49.1945, accuracy 0.5081, precision 0.5330, recall 0.6721, f1-score 0.5945, epoch time: 19.8112 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 48.8228, accuracy 0.5118, precision 0.5367, recall 0.6582, f1-score 0.5913, epoch time: 18.9924 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 38.8044 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 38.80 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 48.8228, accuracy 0.5118, precision 0.5347, recall 0.6782, f1-score 0.5980, epoch time: 20.0900 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 45.7249, accuracy 0.5428, precision 0.5595, recall 0.6852, f1-score 0.6160, epoch time: 19.2173 s, GPU Memory: Allocated: 419.42 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 39.3081 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 39.31 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 1/2, train loss 49.0123, accuracy 0.5099, precision 0.5468, recall 0.6652, f1-score 0.6002, epoch time: 20.7364 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Epoch: 2/2, train loss 48.0247, accuracy 0.5198, precision 0.5558, recall 0.6562, f1-score 0.6018, epoch time: 19.2456 s, GPU Memory: Allocated: 420.94 MB, Reserved: 2130.00 MB\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Total Training Time: 39.9829 seconds\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client fit in 39.98 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
            "    out_mssg, updated_context = backend.process_message(message, context)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
            "    raise ex\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
            "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
            "    _, out_mssg, updated_context = ray.get(future)\n",
            "                                   ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/client_app.py\", line 144, in __call__\n",
            "    return self._call(message, context)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/utils.py\", line 27, in new_ffn\n",
            "    return _mod(message, context, _ffn)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/client/mod/centraldp_mods.py\", line 79, in fixedclipping_mod\n",
            "    compute_clip_model_update(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 74, in compute_clip_model_update\n",
            "    clip_inputs_inplace(model_update, clipping_norm)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/common/differential_privacy.py\", line 52, in clip_inputs_inplace\n",
            "    scaling_factor = min(1, clipping_norm / input_norm)\n",
            "                            ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=31363, ip=172.28.0.12, actor_id=7627faab50fef30fe0bdb71f01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x79ab9631d9d0>)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: float division by zero\n",
            "\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 1 results and 4 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.95 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 2.67 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5568181818181818, recall 0.98, f1 0.7101449275362319\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5287356321839081, recall 0.9787234042553191, f1 0.6865671641791045\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5454545454545454, recall 0.9795918367346939, f1 0.7007299270072993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 1078.58s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 45.34014712387257\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 45.5056180114365\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 45.50561801143652\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 45.5056180114365\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 45.5056180114365\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.5404744069912609),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.544943820224719),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.5449438202247191),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.5449438202247191),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.5449438202247191)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m Client eval in 1.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=31363)\u001b[0m precision 0.5, recall 0.9777777777777777, f1 0.6616541353383458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimates the size of a PyTorch model in bytes\n",
        "def estimate_model_size(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.numel() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.numel() * buffer.element_size()\n",
        "    return param_size + buffer_size\n",
        "\n",
        "binary_model = NetNIH().to(DEVICE)\n",
        "model_size_bytes = estimate_model_size(binary_model)\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "num_rounds = 5\n",
        "num_clients = NUM_CLIENTS\n",
        "\n",
        "uplink_per_round_bytes = num_clients * model_size_bytes\n",
        "downlink_per_round_bytes = num_clients * model_size_bytes\n",
        "total_uplink_bytes = num_rounds * uplink_per_round_bytes\n",
        "total_downlink_bytes = num_rounds * downlink_per_round_bytes\n",
        "total_communication_bytes = total_uplink_bytes + total_downlink_bytes\n",
        "\n",
        "uplink_mb = total_uplink_bytes / (1024 * 1024)\n",
        "downlink_mb = total_downlink_bytes / (1024 * 1024)\n",
        "total_mb = total_communication_bytes / (1024 * 1024)\n",
        "\n",
        "print(\"\\n--- Federated Learning Communication Overhead Estimation ---\")\n",
        "print(f\"Estimated model size: {model_size_mb:.2f} MB\")\n",
        "print(f\"Number of clients: {num_clients}\")\n",
        "print(f\"Number of rounds: {num_rounds}\")\n",
        "print(f\"Estimated uplink communication (total): {uplink_mb:.2f} MB\")\n",
        "print(f\"Estimated downlink communication (total): {downlink_mb:.2f} MB\")\n",
        "print(f\"Estimated total communication: {total_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1613140-542e-44f2-9bf0-98e3087ebb07",
        "id": "nkSOddr02hIQ"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Federated Learning Communication Overhead Estimation ---\n",
            "Estimated model size: 99.73 MB\n",
            "Number of clients: 5\n",
            "Number of rounds: 5\n",
            "Estimated uplink communication (total): 2493.37 MB\n",
            "Estimated downlink communication (total): 2493.37 MB\n",
            "Estimated total communication: 4986.73 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the full centralized train dataset\n",
        "central_trainset = CXRDataset(train_df, \"./nih_images/train/\", transform=transform)\n",
        "\n",
        "# Create the full test dataset\n",
        "central_testset = CXRDataset(test_df, \"./nih_images/test/\", transform=transform)\n",
        "\n",
        "# Now, DataLoaders\n",
        "central_train_loader = DataLoader(central_trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(central_testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Step 1: Rebuild model\n",
        "global_model = NetNIH().to(DEVICE)\n",
        "\n",
        "# Step 2: Load saved weights\n",
        "global_model = load_weights_into_model(global_model, \"/content/FedAvg-DP - round-2-weights.npz\") # model failed from round 2 onwards, load the most final one\n",
        "\n",
        "# Step 3: Run MIA\n",
        "mia_auc = run_membership_inference_attack(global_model, central_train_loader, test_loader)\n",
        "print(f\"Membership Inference Attack AUC: {mia_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f6be47-c07e-46f1-fe3b-74f58aba2eb9",
        "id": "QxR4gXZF2hIQ"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/FedAvg-DP - round-2-weights.npz into model successfully.\n",
            "[Privacy Risk] Membership Inference Attack AUC: 0.5029\n",
            "Membership Inference Attack AUC: 0.5029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. FedProx"
      ],
      "metadata": {
        "id": "xgHp94xmKwoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to get parameters and set parameters\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "umcDkeFZOy1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Client class for FedProx\n",
        "class FPClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.global_params = None\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        self.global_params = copy.deepcopy(self.net).parameters()\n",
        "        fit_start_time = time.time()\n",
        "        train(self.net, self.trainloader, epochs=2, strategy=\"fed_prox\", global_params=self.global_params, config=config)\n",
        "        fit_end_time = time.time()\n",
        "        fit_duration = fit_end_time - fit_start_time\n",
        "        print(f\"Client fit in {fit_duration:.2f} seconds.\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        eval_start_time = time.time()\n",
        "        loss, accuracy, precision, recall, f1  = test(self.net, self.valloader)\n",
        "        eval_end_time = time.time()\n",
        "        eval_duration = eval_end_time - eval_start_time\n",
        "        print(f\"Client eval in {eval_duration:.2f} seconds.\")\n",
        "        print(f\"precision {precision}, recall {recall}, f1 {f1}\")\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "UCM941oUOyz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Flower client representing a single organization\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = NetNIH().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "    return FPClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "FPclient = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "XVEmMxSQOyxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "W4W4WJj9Oyvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saves the final model and retrieves model parameters\n",
        "class SaveModelStrategy(flwr.server.strategy.FedProx):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round,\n",
        "        results,\n",
        "        failures,\n",
        "    ):\n",
        "\n",
        "        # Call aggregate_fit from base class (FedProx) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            aggregated_ndarrays: list[np.ndarray] = flwr.common.parameters_to_ndarrays(\n",
        "                aggregated_parameters\n",
        "            )\n",
        "\n",
        "            print(f\"FedProx - Saving round {server_round} aggregated_ndarrays...\")\n",
        "            np.savez(f\"FedProx - round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
        "\n",
        "        return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "\n",
        "# Create strategy and pass into ServerApp\n",
        "def server_fn(context):\n",
        "    FPstrategy = SaveModelStrategy(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=1.0,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=5,  # Never sample less than 5 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=5,  # Wait until all 5 clients are available\n",
        "        evaluate_metrics_aggregation_fn=weighted_average, # metric aggregation function\n",
        "        proximal_mu=0.3,\n",
        "    )\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "    return ServerAppComponents(strategy=FPstrategy, config=config)\n",
        "\n",
        "\n",
        "FPserver = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "j0EFmEbPcYjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ],
      "metadata": {
        "id": "ggVI7LSe8dG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FL simulation\n",
        "run_simulation(\n",
        "    server_app=FPserver,\n",
        "    client_app=FPclient,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "id": "kDCq3IJw8dEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca844d0-36b1-4c69-9dcb-7911e373b966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=4609)\u001b[0m 2025-04-26 01:15:02.768746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=4609)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=4609)\u001b[0m E0000 00:00:1745630102.791569    4609 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=4609)\u001b[0m E0000 00:00:1745630102.798052    4609 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6948, accuracy 0.5527, precision 0.5599, recall 0.9648, f1-score 0.7086, epoch time: 23.2829 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6785, accuracy 0.5923, precision 0.5847, recall 0.9560, f1-score 0.7256, epoch time: 20.0687 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 43.3524 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 43.35 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.7034, accuracy 0.5489, precision 0.5521, recall 0.9843, f1-score 0.7074, epoch time: 19.4945 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6860, accuracy 0.5539, precision 0.5539, recall 1.0000, f1-score 0.7129, epoch time: 20.0117 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 39.5070 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 39.51 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6977, accuracy 0.5254, precision 0.5321, recall 0.9561, f1-score 0.6837, epoch time: 19.7898 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.7062, accuracy 0.5477, precision 0.5506, recall 0.8545, f1-score 0.6697, epoch time: 19.8090 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 39.5997 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 39.60 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6967, accuracy 0.5242, precision 0.5308, recall 0.9560, f1-score 0.6826, epoch time: 20.2208 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6922, accuracy 0.5341, precision 0.5395, recall 0.8843, f1-score 0.6702, epoch time: 19.2648 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 39.4865 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 39.49 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6918, accuracy 0.5519, precision 0.5548, recall 0.9598, f1-score 0.7032, epoch time: 20.5015 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6921, accuracy 0.5531, precision 0.5532, recall 0.9978, f1-score 0.7118, epoch time: 19.0373 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 39.5395 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 39.54 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx - Saving round 1 aggregated_ndarrays...\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.08 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.58 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5617977528089888, recall 1.0, f1 0.7194244604316546\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.93 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5280898876404494, recall 1.0, f1 0.6911764705882353\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.550561797752809, recall 1.0, f1 0.7101449275362319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5, recall 1.0, f1 0.6666666666666666\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6831, accuracy 0.5638, precision 0.5638, recall 1.0000, f1-score 0.7211, epoch time: 20.1062 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6797, accuracy 0.5886, precision 0.5877, recall 0.9055, f1-score 0.7128, epoch time: 18.9322 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 39.0391 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 39.04 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6896, accuracy 0.5539, precision 0.5539, recall 1.0000, f1-score 0.7129, epoch time: 20.1273 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6915, accuracy 0.5551, precision 0.5553, recall 0.9888, f1-score 0.7112, epoch time: 18.8488 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.9768 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.98 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6873, accuracy 0.5465, precision 0.5460, recall 0.9192, f1-score 0.6850, epoch time: 19.8604 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6735, accuracy 0.5861, precision 0.5780, recall 0.8476, f1-score 0.6873, epoch time: 18.8992 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.7604 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.76 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6871, accuracy 0.5539, precision 0.5503, recall 0.9120, f1-score 0.6864, epoch time: 19.9216 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6695, accuracy 0.6084, precision 0.5963, recall 0.8310, f1-score 0.6944, epoch time: 18.8683 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.7907 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.79 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6902, accuracy 0.5506, precision 0.5520, recall 0.9955, f1-score 0.7102, epoch time: 19.7198 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6864, accuracy 0.5642, precision 0.5616, recall 0.9665, f1-score 0.7104, epoch time: 18.9776 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.6982 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.70 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx - Saving round 2 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.14 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6136363636363636, recall 1.0, f1 0.7605633802816901\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5714285714285714, recall 0.96, f1 0.7164179104477612\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5357142857142857, recall 0.9574468085106383, f1 0.6870229007633588\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.79 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5714285714285714, recall 0.9795918367346939, f1 0.7218045112781954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.17 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5116279069767442, recall 0.9777777777777777, f1 0.6717557251908397\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6746, accuracy 0.5849, precision 0.5904, recall 0.8615, f1-score 0.7006, epoch time: 19.2957 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6655, accuracy 0.5960, precision 0.5859, recall 0.9670, f1-score 0.7297, epoch time: 19.2405 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.5370 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.54 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6826, accuracy 0.5477, precision 0.5520, recall 0.9732, f1-score 0.7045, epoch time: 18.9497 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6711, accuracy 0.5651, precision 0.5680, recall 0.8971, f1-score 0.6956, epoch time: 19.2703 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.2209 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.22 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6682, accuracy 0.5688, precision 0.5669, recall 0.8314, f1-score 0.6742, epoch time: 19.2604 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6737, accuracy 0.6146, precision 0.6078, recall 0.7945, f1-score 0.6887, epoch time: 19.4440 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.7053 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.71 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6645, accuracy 0.5923, precision 0.5752, recall 0.9120, f1-score 0.7055, epoch time: 19.0098 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6614, accuracy 0.6146, precision 0.6075, recall 0.7917, f1-score 0.6874, epoch time: 19.4153 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.4260 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.43 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6837, accuracy 0.5617, precision 0.5631, recall 0.9263, f1-score 0.7004, epoch time: 18.9038 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6686, accuracy 0.5802, precision 0.5754, recall 0.9196, f1-score 0.7079, epoch time: 19.4959 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.4006 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.40 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx - Saving round 3 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.90 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.625, recall 0.8333333333333334, f1 0.7142857142857143\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.85 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5507246376811594, recall 0.76, f1 0.6386554621848739\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.86 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6111111111111112, recall 0.9361702127659575, f1 0.7394957983193278\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.81 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6307692307692307, recall 0.8367346938775511, f1 0.7192982456140351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.66 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5970149253731343, recall 0.8888888888888888, f1 0.7142857142857143\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6715, accuracy 0.6022, precision 0.5980, recall 0.8989, f1-score 0.7182, epoch time: 19.0191 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6560, accuracy 0.6245, precision 0.6176, recall 0.8769, f1-score 0.7248, epoch time: 19.9305 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.9504 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.95 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6771, accuracy 0.5799, precision 0.5752, recall 0.9239, f1-score 0.7090, epoch time: 18.8331 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6665, accuracy 0.5836, precision 0.5837, recall 0.8658, f1-score 0.6973, epoch time: 19.7519 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.5860 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.59 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6700, accuracy 0.5936, precision 0.5837, recall 0.8453, f1-score 0.6906, epoch time: 18.8518 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6592, accuracy 0.6010, precision 0.5897, recall 0.8430, f1-score 0.6939, epoch time: 19.8277 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.6802 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.68 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6629, accuracy 0.6072, precision 0.5997, recall 0.8009, f1-score 0.6858, epoch time: 19.0113 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6521, accuracy 0.6171, precision 0.6020, recall 0.8403, f1-score 0.7014, epoch time: 19.7285 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.7406 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.74 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6824, accuracy 0.5864, precision 0.5811, recall 0.9040, f1-score 0.7074, epoch time: 18.8289 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6621, accuracy 0.5926, precision 0.5843, recall 0.9129, f1-score 0.7125, epoch time: 19.9444 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.7743 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.77 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx - Saving round 4 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6461538461538462, recall 0.7777777777777778, f1 0.7058823529411765\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.5555555555555556, recall 0.7, f1 0.6194690265486725\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6307692307692307, recall 0.8723404255319149, f1 0.7321428571428571\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.66 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6290322580645161, recall 0.7959183673469388, f1 0.7027027027027027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.86 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6290322580645161, recall 0.8666666666666667, f1 0.7289719626168224\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6667, accuracy 0.5998, precision 0.6038, recall 0.8440, f1-score 0.7039, epoch time: 18.8349 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6573, accuracy 0.6072, precision 0.5991, recall 0.9165, f1-score 0.7246, epoch time: 19.7980 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.6336 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.63 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6635, accuracy 0.5737, precision 0.5801, recall 0.8345, f1-score 0.6844, epoch time: 18.7606 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6501, accuracy 0.6121, precision 0.6074, recall 0.8479, f1-score 0.7077, epoch time: 19.6421 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.4036 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.40 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6607, accuracy 0.5936, precision 0.5827, recall 0.8545, f1-score 0.6929, epoch time: 18.7349 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6509, accuracy 0.6283, precision 0.6257, recall 0.7644, f1-score 0.6881, epoch time: 19.7571 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.4927 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.49 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6564, accuracy 0.6059, precision 0.5976, recall 0.8079, f1-score 0.6870, epoch time: 18.6800 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6662, accuracy 0.6109, precision 0.6077, recall 0.7708, f1-score 0.6796, epoch time: 19.8010 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 38.4819 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 38.48 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 1/2, train loss 0.6627, accuracy 0.6000, precision 0.5925, recall 0.8862, f1-score 0.7102, epoch time: 24.6023 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Epoch: 2/2, train loss 0.6444, accuracy 0.6333, precision 0.6193, recall 0.8750, f1-score 0.7253, epoch time: 24.3261 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Total Training Time: 48.9293 seconds\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client fit in 48.93 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx - Saving round 5 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.91 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.7169811320754716, recall 0.7037037037037037, f1 0.7102803738317757\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.576271186440678, recall 0.68, f1 0.6238532110091743\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6896551724137931, recall 0.851063829787234, f1 0.7619047619047619\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.27 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.6727272727272727, recall 0.7551020408163265, f1 0.7115384615384616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 1078.70s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6917115371980322\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6845397539144747\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.6684342028853599\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.6580016122566775\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.6565461494860131\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.5494382022471911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.5673657927590512),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.6097877652933833),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.618701622971286),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.6457178526841448)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m Client eval in 2.14 seconds.\n",
            "\u001b[36m(ClientAppActor pid=4609)\u001b[0m precision 0.625, recall 0.7777777777777778, f1 0.693069306930693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimates the size of a PyTorch model in bytes\n",
        "def estimate_model_size(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.numel() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.numel() * buffer.element_size()\n",
        "    return param_size + buffer_size\n",
        "\n",
        "binary_model = NetNIH().to(DEVICE)\n",
        "model_size_bytes = estimate_model_size(binary_model)\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "num_rounds = 5\n",
        "num_clients = NUM_CLIENTS\n",
        "\n",
        "uplink_per_round_bytes = num_clients * model_size_bytes\n",
        "downlink_per_round_bytes = num_clients * model_size_bytes\n",
        "total_uplink_bytes = num_rounds * uplink_per_round_bytes\n",
        "total_downlink_bytes = num_rounds * downlink_per_round_bytes\n",
        "total_communication_bytes = total_uplink_bytes + total_downlink_bytes\n",
        "\n",
        "uplink_mb = total_uplink_bytes / (1024 * 1024)\n",
        "downlink_mb = total_downlink_bytes / (1024 * 1024)\n",
        "total_mb = total_communication_bytes / (1024 * 1024)\n",
        "\n",
        "print(\"\\n--- Federated Learning Communication Overhead Estimation ---\")\n",
        "print(f\"Estimated model size: {model_size_mb:.2f} MB\")\n",
        "print(f\"Number of clients: {num_clients}\")\n",
        "print(f\"Number of rounds: {num_rounds}\")\n",
        "print(f\"Estimated uplink communication (total): {uplink_mb:.2f} MB\")\n",
        "print(f\"Estimated downlink communication (total): {downlink_mb:.2f} MB\")\n",
        "print(f\"Estimated total communication: {total_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVNiTuo6dT8E",
        "outputId": "c5316243-01aa-4e79-dd1f-b2ac5551045b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Federated Learning Communication Overhead Estimation ---\n",
            "Estimated model size: 99.73 MB\n",
            "Number of clients: 5\n",
            "Number of rounds: 5\n",
            "Estimated uplink communication (total): 2493.37 MB\n",
            "Estimated downlink communication (total): 2493.37 MB\n",
            "Estimated total communication: 4986.73 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the full centralized train dataset\n",
        "central_trainset = CXRDataset(train_df, \"./nih_images/train/\", transform=transform)\n",
        "\n",
        "# Create the full test dataset\n",
        "central_testset = CXRDataset(test_df, \"./nih_images/test/\", transform=transform)\n",
        "\n",
        "# Now, DataLoaders\n",
        "central_train_loader = DataLoader(central_trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(central_testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Step 1: Rebuild model\n",
        "global_model = NetNIH().to(DEVICE)\n",
        "\n",
        "# Step 2: Load saved weights\n",
        "global_model_fp = load_weights_into_model(global_model, \"/content/FedProx - round-5-weights.npz\")\n",
        "\n",
        "# Step 3: Run MIA\n",
        "mia_auc = run_membership_inference_attack(global_model_fp, central_train_loader, test_loader)\n",
        "print(f\"Membership Inference Attack AUC: {mia_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEYRCVHwqQKq",
        "outputId": "c1d25881-e3fb-4db5-92be-11eaa94f89d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/FedProx - round-5-weights.npz into model successfully.\n",
            "[Privacy Risk] Membership Inference Attack AUC: 0.5504\n",
            "Membership Inference Attack AUC: 0.5504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. FedProx-DP"
      ],
      "metadata": {
        "id": "_XsOGrUHGF2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to get parameters and set parameters\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "Gp_GP6VPGF2F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Client class for FedProx\n",
        "class FPClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.global_params = None\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        self.global_params = copy.deepcopy(self.net).parameters()\n",
        "        fit_start_time = time.time()\n",
        "        train(self.net, self.trainloader, epochs=2, strategy=\"fed_prox\", global_params=self.global_params, config=config)\n",
        "        fit_end_time = time.time()\n",
        "        fit_duration = fit_end_time - fit_start_time\n",
        "        print(f\"Client fit in {fit_duration:.2f} seconds.\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        eval_start_time = time.time()\n",
        "        loss, accuracy, precision, recall, f1  = test(self.net, self.valloader)\n",
        "        eval_end_time = time.time()\n",
        "        eval_duration = eval_end_time - eval_start_time\n",
        "        print(f\"Client eval in {eval_duration:.2f} seconds.\")\n",
        "        print(f\"precision {precision}, recall {recall}, f1 {f1}\")\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "F5tCbe8cGF2F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Flower client representing a single organization\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = NetNIH().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "    return FPClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "FPclient = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "g2fU0mxuGF2F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "o5GbWUieGF2G"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saves the final model and retrieves model parameters\n",
        "class SaveModelStrategy(flwr.server.strategy.FedProx):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round,\n",
        "        results,\n",
        "        failures,\n",
        "    ):\n",
        "\n",
        "        # Call aggregate_fit from base class (FedProx) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            aggregated_ndarrays: list[np.ndarray] = flwr.common.parameters_to_ndarrays(\n",
        "                aggregated_parameters\n",
        "            )\n",
        "\n",
        "            print(f\"FedProx-DP - Saving round {server_round} aggregated_ndarrays...\")\n",
        "            np.savez(f\"FedProx-DP - round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
        "\n",
        "        return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "\n",
        "# Create strategy and pass into ServerApp\n",
        "def server_fn(context):\n",
        "    FPstrategy = SaveModelStrategy(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=1.0,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=5,  # Never sample less than 5 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=5,  # Wait until all 5 clients are available\n",
        "        evaluate_metrics_aggregation_fn=weighted_average, # metric aggregation function\n",
        "        proximal_mu=0.3,\n",
        "    )\n",
        "     # === Wrap in client-side DP fixed clipping ===\n",
        "    dp_strategy = DifferentialPrivacyClientSideFixedClipping(\n",
        "        FPstrategy,\n",
        "        noise_multiplier=1.0,    #  (tune as needed)\n",
        "        clipping_norm=1.0,       # C (tune as needed)\n",
        "        num_sampled_clients=5,   # number of clients per round\n",
        "    )\n",
        "\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "    return ServerAppComponents(strategy=dp_strategy, config=config)\n",
        "\n",
        "\n",
        "FPserver = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "Q9Xth3aDGF2G"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ],
      "metadata": {
        "id": "BrpqcQI6GF2G"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FL simulation\n",
        "run_simulation(\n",
        "    server_app=FPserver,\n",
        "    client_app=FPclient,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9543ab-c0c9-4a02-c65a-1259506a848c",
        "id": "-4s6cElTGF2G"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=40913)\u001b[0m 2025-04-26 03:26:55.674782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=40913)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=40913)\u001b[0m E0000 00:00:1745638015.708294   40913 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=40913)\u001b[0m E0000 00:00:1745638015.719181   40913 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 0.6873, accuracy 0.5613, precision 0.5645, recall 0.9714, f1-score 0.7141, epoch time: 21.7497 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 0.6913, accuracy 0.5638, precision 0.5638, recall 1.0000, f1-score 0.7211, epoch time: 20.4369 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 42.1873 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 42.19 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 0.6930, accuracy 0.5527, precision 0.5536, recall 0.9933, f1-score 0.7110, epoch time: 19.9572 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 0.6854, accuracy 0.5440, precision 0.5518, recall 0.9418, f1-score 0.6959, epoch time: 20.3936 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.3517 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.35 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 0.7037, accuracy 0.5489, precision 0.5516, recall 0.8522, f1-score 0.6697, epoch time: 20.4543 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 0.6812, accuracy 0.5663, precision 0.5556, recall 0.9584, f1-score 0.7034, epoch time: 20.0360 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.4913 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.49 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 0.6927, accuracy 0.5514, precision 0.5516, recall 0.8657, f1-score 0.6739, epoch time: 21.1266 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 0.6752, accuracy 0.5762, precision 0.5643, recall 0.9144, f1-score 0.6979, epoch time: 19.1420 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.2694 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.27 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 0.6985, accuracy 0.5506, precision 0.5533, recall 0.9732, f1-score 0.7055, epoch time: 21.0496 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 0.6891, accuracy 0.5531, precision 0.5531, recall 1.0000, f1-score 0.7122, epoch time: 19.1957 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.2461 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.25 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx-DP - Saving round 1 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.51 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.1111111111111111, f1 0.2\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.97 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.25, recall 0.02, f1 0.037037037037037035\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.97 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.75, recall 0.06382978723404255, f1 0.11764705882352941\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.94 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.5, recall 0.02040816326530612, f1 0.0392156862745098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.29 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.25, recall 0.044444444444444446, f1 0.07547169811320754\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 56.2188, accuracy 0.4374, precision 0.5200, recall 0.0286, f1-score 0.0542, epoch time: 19.6633 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 56.1338, accuracy 0.4387, precision 0.5833, recall 0.0154, f1-score 0.0300, epoch time: 19.6611 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.3254 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.33 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 55.6382, accuracy 0.4436, precision 0.4925, recall 0.1477, f1-score 0.2272, epoch time: 19.2117 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 55.3903, accuracy 0.4461, precision 0.5000, recall 0.0157, f1-score 0.0304, epoch time: 19.7870 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 38.9994 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.00 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 52.1245, accuracy 0.4771, precision 0.5161, recall 0.4065, f1-score 0.4548, epoch time: 19.2166 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 48.5750, accuracy 0.5143, precision 0.5267, recall 0.9330, f1-score 0.6733, epoch time: 19.9488 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.1663 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.17 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 47.7843, accuracy 0.5204, precision 0.5316, recall 0.8750, f1-score 0.6614, epoch time: 19.3844 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 46.7162, accuracy 0.5328, precision 0.5347, recall 0.9815, f1-score 0.6922, epoch time: 20.4186 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.8039 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.80 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 50.4818, accuracy 0.4926, precision 0.5615, recall 0.3772, f1-score 0.4513, epoch time: 19.1871 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 55.1852, accuracy 0.4481, precision 0.5046, recall 0.1228, f1-score 0.1975, epoch time: 20.2274 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.4154 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.42 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx-DP - Saving round 2 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.90 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.3333333333333333, recall 0.018518518518518517, f1 0.03508771929824561\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.45 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.6, recall 0.06382978723404255, f1 0.11538461538461539\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.13 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.02040816326530612, f1 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.5, recall 0.022222222222222223, f1 0.0425531914893617\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 53.6555, accuracy 0.4634, precision 0.5539, recall 0.2484, f1-score 0.3429, epoch time: 19.3889 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 53.9033, accuracy 0.4610, precision 0.5439, recall 0.2725, f1-score 0.3631, epoch time: 20.0095 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.3995 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.40 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 52.1685, accuracy 0.4783, precision 0.5650, recall 0.2528, f1-score 0.3493, epoch time: 19.6491 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 53.5316, accuracy 0.4647, precision 0.5349, recall 0.2573, f1-score 0.3474, epoch time: 19.6349 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.2850 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.29 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 55.6382, accuracy 0.4436, precision 0.4630, recall 0.2309, f1-score 0.3082, epoch time: 19.9239 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 53.1599, accuracy 0.4684, precision 0.5088, recall 0.2656, f1-score 0.3490, epoch time: 19.4468 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.3717 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.37 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 53.7794, accuracy 0.4622, precision 0.4958, recall 0.2731, f1-score 0.3522, epoch time: 20.2295 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 50.3098, accuracy 0.4969, precision 0.5637, recall 0.2662, f1-score 0.3616, epoch time: 19.0757 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.3060 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.31 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 51.4815, accuracy 0.4852, precision 0.5529, recall 0.3616, f1-score 0.4372, epoch time: 20.1855 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 47.2840, accuracy 0.5272, precision 0.5557, recall 0.7232, f1-score 0.6285, epoch time: 19.2059 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.3922 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.39 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx-DP - Saving round 3 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.50 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.6, recall 0.05555555555555555, f1 0.1016949152542373\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.10 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.4, recall 0.08, f1 0.13333333333333333\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.86 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.8333333333333334, recall 0.10638297872340426, f1 0.18867924528301888\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.7142857142857143, recall 0.10204081632653061, f1 0.17857142857142858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.7, recall 0.15555555555555556, f1 0.2545454545454545\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 52.1685, accuracy 0.4783, precision 0.5702, recall 0.3033, f1-score 0.3960, epoch time: 20.5215 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 53.2838, accuracy 0.4672, precision 0.5527, recall 0.2879, f1-score 0.3786, epoch time: 19.5381 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.0605 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.06 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 52.4164, accuracy 0.4758, precision 0.5588, recall 0.2550, f1-score 0.3502, epoch time: 20.1291 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 50.5576, accuracy 0.4944, precision 0.5783, recall 0.3221, f1-score 0.4138, epoch time: 19.1464 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.2763 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.28 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 48.9467, accuracy 0.5105, precision 0.5805, recall 0.3164, f1-score 0.4096, epoch time: 20.3876 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 51.1772, accuracy 0.4882, precision 0.5424, recall 0.2956, f1-score 0.3827, epoch time: 20.1329 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.5215 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.52 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 49.0706, accuracy 0.5093, precision 0.5726, recall 0.3287, f1-score 0.4176, epoch time: 19.7714 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 48.6989, accuracy 0.5130, precision 0.5816, recall 0.3218, f1-score 0.4143, epoch time: 20.5736 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.3460 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.35 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 51.3580, accuracy 0.4864, precision 0.5640, recall 0.3147, f1-score 0.4040, epoch time: 19.5548 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 50.0000, accuracy 0.5000, precision 0.5837, recall 0.3348, f1-score 0.4255, epoch time: 20.7014 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.2571 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.26 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx-DP - Saving round 4 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.95 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.91 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.64 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.02 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.90 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 54.6468, accuracy 0.4535, precision 0.5412, recall 0.2022, f1-score 0.2944, epoch time: 20.0980 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 51.4250, accuracy 0.4857, precision 0.5990, recall 0.2659, f1-score 0.3683, epoch time: 20.0308 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.1298 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.13 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 52.4164, accuracy 0.4758, precision 0.5606, recall 0.2483, f1-score 0.3442, epoch time: 20.6010 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 53.0359, accuracy 0.4696, precision 0.5450, recall 0.2573, f1-score 0.3495, epoch time: 19.5326 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.1344 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.13 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 51.7968, accuracy 0.4820, precision 0.5381, recall 0.2448, f1-score 0.3365, epoch time: 20.6064 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 53.7794, accuracy 0.4622, precision 0.4972, recall 0.2055, f1-score 0.2908, epoch time: 19.5584 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 40.1658 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 40.17 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 52.5403, accuracy 0.4746, precision 0.5194, recall 0.2477, f1-score 0.3354, epoch time: 20.5320 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 53.2838, accuracy 0.4672, precision 0.5053, recall 0.2199, f1-score 0.3065, epoch time: 19.3888 s, GPU Memory: Allocated: 420.12 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.9216 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 1/2, train loss 53.0864, accuracy 0.4691, precision 0.5500, recall 0.2210, f1-score 0.3153, epoch time: 20.2996 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Epoch: 2/2, train loss 51.9753, accuracy 0.4802, precision 0.5763, recall 0.2277, f1-score 0.3264, epoch time: 19.4002 s, GPU Memory: Allocated: 422.00 MB, Reserved: 2076.00 MB\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Total Training Time: 39.7008 seconds\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client fit in 39.70 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedProx-DP - Saving round 5 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.90 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.04, f1 0.07692307692307693\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 0.3333333333333333, recall 0.02040816326530612, f1 0.038461538461538464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 1099.74s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 54.436308164370345\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 55.168539512339\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 52.70661676299706\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 54.943820411215405\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 54.94382041121541\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.4551560549313358),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.44831460674157303),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.4729338327091136),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.450561797752809),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.45056179775280897)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m Client eval in 2.61 seconds.\n",
            "\u001b[36m(ClientAppActor pid=40913)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimates the size of a PyTorch model in bytes\n",
        "def estimate_model_size(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.numel() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.numel() * buffer.element_size()\n",
        "    return param_size + buffer_size\n",
        "\n",
        "binary_model = NetNIH().to(DEVICE)\n",
        "model_size_bytes = estimate_model_size(binary_model)\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "num_rounds = 5\n",
        "num_clients = NUM_CLIENTS\n",
        "\n",
        "uplink_per_round_bytes = num_clients * model_size_bytes\n",
        "downlink_per_round_bytes = num_clients * model_size_bytes\n",
        "total_uplink_bytes = num_rounds * uplink_per_round_bytes\n",
        "total_downlink_bytes = num_rounds * downlink_per_round_bytes\n",
        "total_communication_bytes = total_uplink_bytes + total_downlink_bytes\n",
        "\n",
        "uplink_mb = total_uplink_bytes / (1024 * 1024)\n",
        "downlink_mb = total_downlink_bytes / (1024 * 1024)\n",
        "total_mb = total_communication_bytes / (1024 * 1024)\n",
        "\n",
        "print(\"\\n--- Federated Learning Communication Overhead Estimation ---\")\n",
        "print(f\"Estimated model size: {model_size_mb:.2f} MB\")\n",
        "print(f\"Number of clients: {num_clients}\")\n",
        "print(f\"Number of rounds: {num_rounds}\")\n",
        "print(f\"Estimated uplink communication (total): {uplink_mb:.2f} MB\")\n",
        "print(f\"Estimated downlink communication (total): {downlink_mb:.2f} MB\")\n",
        "print(f\"Estimated total communication: {total_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9d291b-0ee5-440d-890e-b173df9c8d18",
        "id": "5xplBde6GF2G"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Federated Learning Communication Overhead Estimation ---\n",
            "Estimated model size: 99.73 MB\n",
            "Number of clients: 5\n",
            "Number of rounds: 5\n",
            "Estimated uplink communication (total): 2493.37 MB\n",
            "Estimated downlink communication (total): 2493.37 MB\n",
            "Estimated total communication: 4986.73 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the full centralized train dataset\n",
        "central_trainset = CXRDataset(train_df, \"./nih_images/train/\", transform=transform)\n",
        "\n",
        "# Create the full test dataset\n",
        "central_testset = CXRDataset(test_df, \"./nih_images/test/\", transform=transform)\n",
        "\n",
        "# Now, DataLoaders\n",
        "central_train_loader = DataLoader(central_trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(central_testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Step 1: Rebuild model\n",
        "global_model = NetNIH().to(DEVICE)\n",
        "\n",
        "# Step 2: Load saved weights\n",
        "global_model_fp = load_weights_into_model(global_model, \"/content/FedProx-DP - round-5-weights.npz\")\n",
        "\n",
        "# Step 3: Run MIA\n",
        "mia_auc = run_membership_inference_attack(global_model_fp, central_train_loader, test_loader)\n",
        "print(f\"Membership Inference Attack AUC: {mia_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48049f79-4279-4faa-d980-97261b9f71e2",
        "id": "roeRTmbJGF2G"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/FedProx-DP - round-5-weights.npz into model successfully.\n",
            "[Privacy Risk] Membership Inference Attack AUC: 0.4994\n",
            "Membership Inference Attack AUC: 0.4994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Fed Adam"
      ],
      "metadata": {
        "id": "jR8fxEdFnaKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to get parameters and set parameters\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "j4M9zQ_RYTx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Client class for FedAdams\n",
        "class FDClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.global_params = None\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        self.global_params = copy.deepcopy(self.net).parameters()\n",
        "        fit_start_time = time.time()\n",
        "        train(self.net, self.trainloader, epochs=2, strategy=\"fed\", global_params=self.global_params) #train\n",
        "        fit_end_time = time.time()\n",
        "        fit_duration = fit_end_time - fit_start_time\n",
        "        print(f\"Client fit in {fit_duration:.2f} seconds.\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        eval_start_time = time.time()\n",
        "        loss, accuracy, precision, recall, f1  = test(self.net, self.valloader)\n",
        "        eval_end_time = time.time()\n",
        "        eval_duration = eval_end_time - eval_start_time\n",
        "        print(f\"Client eval in {eval_duration:.2f} seconds.\")\n",
        "        print(f\"precision {precision}, recall {recall}, f1 {f1}\")\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "aldcT8vsnsGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Flower client representing a single organization\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = NetNIH().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "    return FDClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "FDclient = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "HRUVqSwhnvi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "2wibqOkUnyBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saves the final model and retrieves model parameters\n",
        "class SaveModelStrategy(flwr.server.strategy.FedAdam):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round,\n",
        "        results,\n",
        "        failures,\n",
        "    ):\n",
        "\n",
        "        # Call aggregate_fit from base class (FedAdam) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            aggregated_ndarrays: list[np.ndarray] = flwr.common.parameters_to_ndarrays(\n",
        "                aggregated_parameters\n",
        "            )\n",
        "\n",
        "            print(f\"FedAdam - Saving round {server_round} aggregated_ndarrays...\")\n",
        "            np.savez(f\"FedAdam - round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
        "\n",
        "        return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "\n",
        "# Create strategy and pass into ServerApp\n",
        "def server_fn(context):\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "    initial_net = NetNIH().to(DEVICE)\n",
        "    initial_params = get_parameters(initial_net)\n",
        "    tensors_as_bytes = [ndarray_to_bytes(ndarray) for ndarray in initial_params]\n",
        "    initial_parameters = Parameters(tensors=tensors_as_bytes, tensor_type=\"numpy.ndarray\")\n",
        "\n",
        "    FDstrategy = SaveModelStrategy(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=1.0,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=5,  # Never sample less than 5 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=5,  # Wait until all 5 clients are available\n",
        "        evaluate_metrics_aggregation_fn=weighted_average, # metric aggregation function\n",
        "        initial_parameters=initial_parameters\n",
        "    )\n",
        "\n",
        "    return ServerAppComponents(strategy=FDstrategy, config=config)\n",
        "\n",
        "\n",
        "FDserver = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "fo9aZQpPeP8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ],
      "metadata": {
        "id": "z0PxTI3wn4Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FL simulation\n",
        "run_simulation(\n",
        "    server_app=FDserver,\n",
        "    client_app=FDclient,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "id": "b4o0QTb1n84G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3080759d-7057-47c6-e097-bbc7b30532ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(pid=10247)\u001b[0m 2025-04-26 01:36:14.401692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=10247)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=10247)\u001b[0m E0000 00:00:1745631374.422219   10247 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=10247)\u001b[0m E0000 00:00:1745631374.428279   10247 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 0.7016, accuracy 0.5564, precision 0.5609, recall 0.9824, f1-score 0.7141, epoch time: 19.4108 s, GPU Memory: Allocated: 519.50 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 0.6827, accuracy 0.5663, precision 0.5659, recall 0.9912, f1-score 0.7204, epoch time: 19.8339 s, GPU Memory: Allocated: 519.50 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 39.2455 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 39.25 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 0.6981, accuracy 0.5527, precision 0.5599, recall 0.8993, f1-score 0.6901, epoch time: 18.6875 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 0.7002, accuracy 0.5527, precision 0.5535, recall 0.9955, f1-score 0.7114, epoch time: 19.7489 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.4372 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.44 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 0.7039, accuracy 0.5242, precision 0.5359, recall 0.8453, f1-score 0.6559, epoch time: 18.8959 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 0.6980, accuracy 0.5291, precision 0.5355, recall 0.9238, f1-score 0.6780, epoch time: 19.7018 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.5985 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.60 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 0.6996, accuracy 0.5279, precision 0.5352, recall 0.8981, f1-score 0.6707, epoch time: 18.8988 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 0.6923, accuracy 0.5613, precision 0.5663, recall 0.7708, f1-score 0.6529, epoch time: 19.8969 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7965 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.80 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 0.7119, accuracy 0.5494, precision 0.5566, recall 0.9107, f1-score 0.6909, epoch time: 18.7681 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 0.6942, accuracy 0.5531, precision 0.5531, recall 1.0000, f1-score 0.7122, epoch time: 19.8356 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.6044 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.60 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam - Saving round 1 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 2.50 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.81 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 56.1338, accuracy 0.4387, precision 0.5714, recall 0.0176, f1-score 0.0341, epoch time: 19.9286 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 55.8860, accuracy 0.4411, precision 0.7000, recall 0.0154, f1-score 0.0301, epoch time: 18.8687 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7980 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.80 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 54.5229, accuracy 0.4548, precision 0.5574, recall 0.0761, f1-score 0.1339, epoch time: 19.8614 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 55.1425, accuracy 0.4486, precision 0.5192, recall 0.0604, f1-score 0.1082, epoch time: 18.8764 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7386 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.74 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 53.4077, accuracy 0.4659, precision 0.5200, recall 0.0600, f1-score 0.1077, epoch time: 19.8524 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 52.1685, accuracy 0.4783, precision 0.6034, recall 0.0808, f1-score 0.1426, epoch time: 18.8627 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7158 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.72 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 54.6745, accuracy 0.4523, precision 0.4342, recall 0.0764, f1-score 0.1299, epoch time: 19.8486 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 53.1599, accuracy 0.4684, precision 0.5070, recall 0.2523, f1-score 0.3369, epoch time: 18.9180 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7674 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.77 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 52.5926, accuracy 0.4741, precision 0.6897, recall 0.0893, f1-score 0.1581, epoch time: 19.8751 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 54.3029, accuracy 0.4568, precision 0.5714, recall 0.0714, f1-score 0.1270, epoch time: 18.8069 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.6828 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.68 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam - Saving round 2 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.85 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.99 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 2.27 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 55.7621, accuracy 0.4424, precision 0.5714, recall 0.0440, f1-score 0.0816, epoch time: 18.8150 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 55.1425, accuracy 0.4486, precision 0.6562, recall 0.0462, f1-score 0.0862, epoch time: 19.9716 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7873 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.79 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 55.3903, accuracy 0.4461, precision 0.5000, recall 0.0380, f1-score 0.0707, epoch time: 18.9908 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 54.5229, accuracy 0.4548, precision 0.5897, recall 0.0515, f1-score 0.0947, epoch time: 19.8545 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.8460 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.85 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 52.1685, accuracy 0.4783, precision 0.6667, recall 0.0554, f1-score 0.1023, epoch time: 18.9230 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 54.1512, accuracy 0.4585, precision 0.4231, recall 0.0254, f1-score 0.0479, epoch time: 19.7988 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7226 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.72 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 52.5403, accuracy 0.4746, precision 0.5952, recall 0.0579, f1-score 0.1055, epoch time: 18.8297 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 51.6729, accuracy 0.4833, precision 0.6923, recall 0.0625, f1-score 0.1146, epoch time: 19.8503 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.6807 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.68 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 54.6914, accuracy 0.4531, precision 0.5676, recall 0.0469, f1-score 0.0866, epoch time: 18.8445 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 53.8272, accuracy 0.4617, precision 0.6667, recall 0.0536, f1-score 0.0992, epoch time: 19.8101 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.6555 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.66 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam - Saving round 3 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 2.77 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.80 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 56.2577, accuracy 0.4374, precision 0.5152, recall 0.0374, f1-score 0.0697, epoch time: 19.9779 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 56.0099, accuracy 0.4399, precision 0.5484, recall 0.0374, f1-score 0.0700, epoch time: 19.0004 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.9793 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.98 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 54.7708, accuracy 0.4523, precision 0.5758, recall 0.0425, f1-score 0.0792, epoch time: 19.8743 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 55.3903, accuracy 0.4461, precision 0.5000, recall 0.0358, f1-score 0.0668, epoch time: 18.8559 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.7311 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.73 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 53.6555, accuracy 0.4634, precision 0.5000, recall 0.0439, f1-score 0.0807, epoch time: 20.0854 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 54.0273, accuracy 0.4597, precision 0.4444, recall 0.0277, f1-score 0.0522, epoch time: 19.2262 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 39.3123 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 39.31 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 54.6468, accuracy 0.4535, precision 0.3333, recall 0.0208, f1-score 0.0392, epoch time: 19.7064 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 52.9120, accuracy 0.4709, precision 0.5862, recall 0.0394, f1-score 0.0738, epoch time: 18.9885 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.6958 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.70 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 53.7037, accuracy 0.4630, precision 0.6857, recall 0.0536, f1-score 0.0994, epoch time: 19.2985 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 55.3086, accuracy 0.4469, precision 0.5000, recall 0.0335, f1-score 0.0628, epoch time: 19.0421 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.3416 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.34 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam - Saving round 4 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 2.78 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 55.8860, accuracy 0.4411, precision 0.5714, recall 0.0352, f1-score 0.0663, epoch time: 18.8270 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 56.2577, accuracy 0.4374, precision 0.5152, recall 0.0374, f1-score 0.0697, epoch time: 19.7923 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.6200 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.62 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 55.1425, accuracy 0.4486, precision 0.5312, recall 0.0380, f1-score 0.0710, epoch time: 18.7535 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 54.7708, accuracy 0.4523, precision 0.6000, recall 0.0336, f1-score 0.0636, epoch time: 20.1430 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 38.8973 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 38.90 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 52.6642, accuracy 0.4734, precision 0.6053, recall 0.0531, f1-score 0.0977, epoch time: 21.5890 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 52.9120, accuracy 0.4709, precision 0.5750, recall 0.0531, f1-score 0.0973, epoch time: 18.8638 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 40.4537 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 40.45 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 53.1599, accuracy 0.4684, precision 0.5714, recall 0.0278, f1-score 0.0530, epoch time: 19.7354 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 52.9120, accuracy 0.4709, precision 0.5926, recall 0.0370, f1-score 0.0697, epoch time: 20.6491 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 40.3853 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 40.39 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 1/2, train loss 54.5679, accuracy 0.4543, precision 0.5833, recall 0.0469, f1-score 0.0868, epoch time: 22.0721 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Epoch: 2/2, train loss 55.3086, accuracy 0.4469, precision 0.5000, recall 0.0379, f1-score 0.0705, epoch time: 19.6467 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Total Training Time: 41.7198 seconds\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client fit in 41.72 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam - Saving round 5 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.89 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 2.70 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 1103.97s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 54.94382041121541\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 54.94382041121541\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 54.94382041121541\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 54.943820411215405\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 54.943820411215405\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.45056179775280897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.45056179775280897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.45056179775280897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.45056179775280897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.45056179775280897)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m Client eval in 1.84 seconds.\n",
            "\u001b[36m(ClientAppActor pid=10247)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimates the size of a PyTorch model in bytes\n",
        "def estimate_model_size(model):\n",
        "    \"\"\"Estimates the size of a PyTorch model in bytes.\"\"\"\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.numel() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.numel() * buffer.element_size()\n",
        "    return param_size + buffer_size\n",
        "\n",
        "binary_model = NetNIH().to(DEVICE)\n",
        "model_size_bytes = estimate_model_size(binary_model)\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "num_rounds = 5\n",
        "num_clients = NUM_CLIENTS\n",
        "\n",
        "uplink_per_round_bytes = num_clients * model_size_bytes\n",
        "downlink_per_round_bytes = num_clients * model_size_bytes\n",
        "total_uplink_bytes = num_rounds * uplink_per_round_bytes\n",
        "total_downlink_bytes = num_rounds * downlink_per_round_bytes\n",
        "total_communication_bytes = total_uplink_bytes + total_downlink_bytes\n",
        "\n",
        "uplink_mb = total_uplink_bytes / (1024 * 1024)\n",
        "downlink_mb = total_downlink_bytes / (1024 * 1024)\n",
        "total_mb = total_communication_bytes / (1024 * 1024)\n",
        "\n",
        "print(\"\\n--- Federated Learning Communication Overhead Estimation ---\")\n",
        "print(f\"Estimated model size: {model_size_mb:.2f} MB\")\n",
        "print(f\"Number of clients: {num_clients}\")\n",
        "print(f\"Number of rounds: {num_rounds}\")\n",
        "print(f\"Estimated uplink communication (total): {uplink_mb:.2f} MB\")\n",
        "print(f\"Estimated downlink communication (total): {downlink_mb:.2f} MB\")\n",
        "print(f\"Estimated total communication: {total_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BgdPH-NeIoq",
        "outputId": "3ebfcf4a-b2d0-4464-d020-5bc137b88597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Federated Learning Communication Overhead Estimation ---\n",
            "Estimated model size: 99.73 MB\n",
            "Number of clients: 5\n",
            "Number of rounds: 5\n",
            "Estimated uplink communication (total): 2493.37 MB\n",
            "Estimated downlink communication (total): 2493.37 MB\n",
            "Estimated total communication: 4986.73 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the full centralized train dataset\n",
        "central_trainset = CXRDataset(train_df, \"./nih_images/train/\", transform=transform)\n",
        "\n",
        "# Create the full test dataset\n",
        "central_testset = CXRDataset(test_df, \"./nih_images/test/\", transform=transform)\n",
        "\n",
        "# Now, DataLoaders\n",
        "central_train_loader = DataLoader(central_trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(central_testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Step 1: Rebuild model\n",
        "global_model = NetNIH().to(DEVICE)\n",
        "\n",
        "# Step 2: Load saved weights\n",
        "global_model_fp = load_weights_into_model(global_model, \"/content/FedAdam - round-5-weights.npz\")\n",
        "\n",
        "# Step 3: Run MIA\n",
        "mia_auc = run_membership_inference_attack(global_model_fp, central_train_loader, test_loader)\n",
        "print(f\"Membership Inference Attack AUC: {mia_auc:.4f}\")"
      ],
      "metadata": {
        "id": "1_DRmj6z4d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e92a661-1090-4840-920c-d8955be889ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/FedAdam - round-5-weights.npz into model successfully.\n",
            "[Privacy Risk] Membership Inference Attack AUC: 0.5000\n",
            "Membership Inference Attack AUC: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IVIdCiUyzeKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Fed Adam-DP"
      ],
      "metadata": {
        "id": "UDgaiiSqNA10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to get parameters and set parameters\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "I7l8JjvyNA11"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Client class for FedAdams\n",
        "class FDClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.global_params = None\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        self.global_params = copy.deepcopy(self.net).parameters()\n",
        "        fit_start_time = time.time()\n",
        "        train(self.net, self.trainloader, epochs=2, strategy=\"fed\", global_params=self.global_params) #train\n",
        "        fit_end_time = time.time()\n",
        "        fit_duration = fit_end_time - fit_start_time\n",
        "        print(f\"Client fit in {fit_duration:.2f} seconds.\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        eval_start_time = time.time()\n",
        "        loss, accuracy, precision, recall, f1  = test(self.net, self.valloader)\n",
        "        eval_end_time = time.time()\n",
        "        eval_duration = eval_end_time - eval_start_time\n",
        "        print(f\"Client eval in {eval_duration:.2f} seconds.\")\n",
        "        print(f\"precision {precision}, recall {recall}, f1 {f1}\")\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "TPeYPv24NA11"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Flower client representing a single organization\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = NetNIH().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "    return FDClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "FDclient = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "KES4_mX3NA11"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "hqb5ZcEwNA11"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saves the final model and retrieves model parameters\n",
        "class SaveModelStrategy(flwr.server.strategy.FedAdam):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round,\n",
        "        results,\n",
        "        failures,\n",
        "    ):\n",
        "\n",
        "        # Call aggregate_fit from base class (FedAdam) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            aggregated_ndarrays: list[np.ndarray] = flwr.common.parameters_to_ndarrays(\n",
        "                aggregated_parameters\n",
        "            )\n",
        "\n",
        "            print(f\"FedAdam-DP - Saving round {server_round} aggregated_ndarrays...\")\n",
        "            np.savez(f\"FedAdam-DP - round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
        "\n",
        "        return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "\n",
        "# Create strategy and pass into ServerApp\n",
        "def server_fn(context):\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "    initial_net = NetNIH().to(DEVICE)\n",
        "    initial_params = get_parameters(initial_net)\n",
        "    tensors_as_bytes = [ndarray_to_bytes(ndarray) for ndarray in initial_params]\n",
        "    initial_parameters = Parameters(tensors=tensors_as_bytes, tensor_type=\"numpy.ndarray\")\n",
        "\n",
        "    FDstrategy = SaveModelStrategy(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=1.0,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=5,  # Never sample less than 5 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=5,  # Wait until all 5 clients are available\n",
        "        evaluate_metrics_aggregation_fn=weighted_average, # metric aggregation function\n",
        "        initial_parameters=initial_parameters\n",
        "    )\n",
        "    # === Wrap in client-side DP fixed clipping ===\n",
        "    dp_strategy = DifferentialPrivacyClientSideFixedClipping(\n",
        "        FDstrategy,\n",
        "        noise_multiplier=1.0,    #  (tune as needed)\n",
        "        clipping_norm=1.0,       # C (tune as needed)\n",
        "        num_sampled_clients=5,   # number of clients per round\n",
        "    )\n",
        "\n",
        "    return ServerAppComponents(strategy=dp_strategy, config=config)\n",
        "\n",
        "\n",
        "FDserver = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "Nn2Bj31PNA11"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ],
      "metadata": {
        "id": "ismNMjgzNA11"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FL simulation\n",
        "run_simulation(\n",
        "    server_app=FDserver,\n",
        "    client_app=FDclient,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0200db53-8b79-45c1-d1ac-9d444a93b573",
        "id": "IXofT1EnNA11"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(pid=50061)\u001b[0m 2025-04-26 03:59:35.334373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=50061)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=50061)\u001b[0m E0000 00:00:1745639975.356389   50061 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=50061)\u001b[0m E0000 00:00:1745639975.362616   50061 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 0.7045, accuracy 0.5601, precision 0.5643, recall 0.9648, f1-score 0.7121, epoch time: 21.6118 s, GPU Memory: Allocated: 519.50 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 0.6950, accuracy 0.5651, precision 0.5645, recall 1.0000, f1-score 0.7216, epoch time: 19.5627 s, GPU Memory: Allocated: 519.50 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 41.1753 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 41.18 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 0.6970, accuracy 0.5502, precision 0.5548, recall 0.9508, f1-score 0.7007, epoch time: 21.0954 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 0.6898, accuracy 0.5527, precision 0.5550, recall 0.9709, f1-score 0.7063, epoch time: 19.1182 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 40.2144 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 40.22 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 0.7097, accuracy 0.5242, precision 0.5319, recall 0.9423, f1-score 0.6800, epoch time: 21.1969 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 0.6862, accuracy 0.5366, precision 0.5366, recall 1.0000, f1-score 0.6984, epoch time: 19.7492 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 40.9470 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 40.95 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 0.6941, accuracy 0.5440, precision 0.5430, recall 0.9352, f1-score 0.6871, epoch time: 20.5108 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 0.6831, accuracy 0.5799, precision 0.5784, recall 0.7940, f1-score 0.6693, epoch time: 20.5886 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 41.1003 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 41.10 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 0.7107, accuracy 0.5432, precision 0.5503, recall 0.9531, f1-score 0.6977, epoch time: 20.3471 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 0.6886, accuracy 0.5543, precision 0.5538, recall 1.0000, f1-score 0.7128, epoch time: 20.4109 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 40.7588 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 40.76 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam-DP - Saving round 1 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.00 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.96 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.97 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.96 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 52.4014, accuracy 0.4758, precision 0.5473, recall 0.4066, f1-score 0.4666, epoch time: 20.2130 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 51.3972, accuracy 0.4857, precision 0.5592, recall 0.4154, f1-score 0.4767, epoch time: 19.2083 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.4221 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.42 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 48.9467, accuracy 0.5105, precision 0.5726, recall 0.4586, f1-score 0.5093, epoch time: 20.1289 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 51.6729, accuracy 0.4833, precision 0.5431, recall 0.4228, f1-score 0.4755, epoch time: 19.3767 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.5066 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.51 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 47.3358, accuracy 0.5266, precision 0.5710, recall 0.4734, f1-score 0.5177, epoch time: 19.5117 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 49.4788, accuracy 0.5043, precision 0.5390, recall 0.5266, f1-score 0.5327, epoch time: 19.7950 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.3076 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.31 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 51.9207, accuracy 0.4808, precision 0.5187, recall 0.4167, f1-score 0.4621, epoch time: 19.1632 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 48.6989, accuracy 0.5130, precision 0.5517, recall 0.4815, f1-score 0.5142, epoch time: 20.1378 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.3021 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.30 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 50.4938, accuracy 0.4951, precision 0.5552, recall 0.4375, f1-score 0.4894, epoch time: 19.2068 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 47.1605, accuracy 0.5284, precision 0.5917, recall 0.4754, f1-score 0.5272, epoch time: 20.2230 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.4306 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.43 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam-DP - Saving round 2 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.32 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.12 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.83 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.89 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 1.0, recall 0.0, f1 0.0\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 48.3271, accuracy 0.5167, precision 0.5937, recall 0.4527, f1-score 0.5137, epoch time: 20.3232 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 54.7708, accuracy 0.4523, precision 0.5187, recall 0.3956, f1-score 0.4489, epoch time: 19.2149 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.5388 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.54 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 50.4337, accuracy 0.4957, precision 0.5595, recall 0.4206, f1-score 0.4802, epoch time: 20.0663 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 49.9380, accuracy 0.5006, precision 0.5595, recall 0.4631, f1-score 0.5067, epoch time: 19.1425 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.2097 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.21 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 51.1772, accuracy 0.4882, precision 0.5287, recall 0.4249, f1-score 0.4712, epoch time: 20.1991 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 50.0620, accuracy 0.4994, precision 0.5406, recall 0.4457, f1-score 0.4886, epoch time: 19.1822 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.3821 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.38 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 48.0848, accuracy 0.5180, precision 0.5516, recall 0.5324, f1-score 0.5418, epoch time: 20.2726 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 50.4139, accuracy 0.4957, precision 0.5233, recall 0.6505, f1-score 0.5800, epoch time: 19.1093 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.3827 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.38 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 52.5926, accuracy 0.4741, precision 0.5312, recall 0.4174, f1-score 0.4675, epoch time: 19.7106 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 51.4382, accuracy 0.4852, precision 0.5427, recall 0.4397, f1-score 0.4858, epoch time: 19.4262 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.1378 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.14 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam-DP - Saving round 3 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.88 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5617977528089888, recall 1.0, f1 0.7194244604316546\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.43 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5280898876404494, recall 1.0, f1 0.6911764705882353\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.98 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.550561797752809, recall 1.0, f1 0.7101449275362319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5, recall 1.0, f1 0.6666666666666666\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 48.8228, accuracy 0.5118, precision 0.5521, recall 0.7099, f1-score 0.6212, epoch time: 19.6343 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 47.3358, accuracy 0.5266, precision 0.5641, recall 0.7055, f1-score 0.6270, epoch time: 19.8026 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.4379 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.44 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 48.6989, accuracy 0.5130, precision 0.5470, recall 0.7025, f1-score 0.6151, epoch time: 19.9915 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 48.9467, accuracy 0.5105, precision 0.5445, recall 0.7114, f1-score 0.6169, epoch time: 19.2842 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.2767 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.28 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 48.8228, accuracy 0.5118, precision 0.5334, recall 0.7182, f1-score 0.6122, epoch time: 20.2066 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 47.5836, accuracy 0.5242, precision 0.5434, recall 0.7090, f1-score 0.6152, epoch time: 19.0921 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.2995 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.30 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 49.4424, accuracy 0.5056, precision 0.5271, recall 0.7431, f1-score 0.6167, epoch time: 20.2032 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 48.0793, accuracy 0.5192, precision 0.5378, recall 0.7245, f1-score 0.6174, epoch time: 19.1562 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.3602 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.36 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 46.9136, accuracy 0.5309, precision 0.5586, recall 0.7232, f1-score 0.6304, epoch time: 20.1715 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 46.2963, accuracy 0.5370, precision 0.5622, recall 0.7366, f1-score 0.6377, epoch time: 19.3818 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.5542 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.55 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam-DP - Saving round 4 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.89 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.91 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5617977528089888, recall 1.0, f1 0.7194244604316546\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.89 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5280898876404494, recall 1.0, f1 0.6911764705882353\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.54 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.550561797752809, recall 1.0, f1 0.7101449275362319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5, recall 1.0, f1 0.6666666666666666\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 47.9554, accuracy 0.5204, precision 0.5518, recall 0.7956, f1-score 0.6517, epoch time: 19.5053 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 44.9814, accuracy 0.5502, precision 0.5697, recall 0.8264, f1-score 0.6744, epoch time: 20.4829 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.9889 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.99 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 46.0618, accuracy 0.5390, precision 0.5573, recall 0.8166, f1-score 0.6624, epoch time: 19.5461 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 46.2206, accuracy 0.5378, precision 0.5564, recall 0.8166, f1-score 0.6618, epoch time: 20.2317 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.7787 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.78 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 46.7162, accuracy 0.5328, precision 0.5433, recall 0.8106, f1-score 0.6506, epoch time: 20.2099 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 47.7076, accuracy 0.5229, precision 0.5368, recall 0.8083, f1-score 0.6452, epoch time: 19.7671 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.9780 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.98 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 48.0793, accuracy 0.5192, precision 0.5330, recall 0.8218, f1-score 0.6466, epoch time: 20.4490 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 46.9641, accuracy 0.5304, precision 0.5412, recall 0.8056, f1-score 0.6474, epoch time: 19.3675 s, GPU Memory: Allocated: 520.09 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.8172 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.82 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 1/2, train loss 47.1605, accuracy 0.5284, precision 0.5494, recall 0.8192, f1-score 0.6577, epoch time: 20.3014 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Epoch: 2/2, train loss 45.8025, accuracy 0.5420, precision 0.5601, recall 0.8013, f1-score 0.6593, epoch time: 19.2716 s, GPU Memory: Allocated: 521.17 MB, Reserved: 2250.00 MB\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Total Training Time: 39.5738 seconds\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client fit in 39.57 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FedAdam-DP - Saving round 5 aggregated_ndarrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.2000 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.92 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.6067415730337079, recall 1.0, f1 0.7552447552447552\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.87 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5617977528089888, recall 1.0, f1 0.7194244604316546\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 1.89 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5280898876404494, recall 1.0, f1 0.6911764705882353\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.34 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.550561797752809, recall 1.0, f1 0.7101449275362319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 1136.36s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 54.94382041121541\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 54.94382041121541\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 45.056179809189324\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 45.056179809189324\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 45.056179809189324\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.45056179775280897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.45056179775280897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.5494382022471911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.5494382022471911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.5494382022471911)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m Client eval in 2.10 seconds.\n",
            "\u001b[36m(ClientAppActor pid=50061)\u001b[0m precision 0.5, recall 1.0, f1 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimates the size of a PyTorch model in bytes\n",
        "def estimate_model_size(model):\n",
        "    \"\"\"Estimates the size of a PyTorch model in bytes.\"\"\"\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.numel() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.numel() * buffer.element_size()\n",
        "    return param_size + buffer_size\n",
        "\n",
        "binary_model = NetNIH().to(DEVICE)\n",
        "model_size_bytes = estimate_model_size(binary_model)\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "num_rounds = 5\n",
        "num_clients = NUM_CLIENTS\n",
        "\n",
        "uplink_per_round_bytes = num_clients * model_size_bytes\n",
        "downlink_per_round_bytes = num_clients * model_size_bytes\n",
        "total_uplink_bytes = num_rounds * uplink_per_round_bytes\n",
        "total_downlink_bytes = num_rounds * downlink_per_round_bytes\n",
        "total_communication_bytes = total_uplink_bytes + total_downlink_bytes\n",
        "\n",
        "uplink_mb = total_uplink_bytes / (1024 * 1024)\n",
        "downlink_mb = total_downlink_bytes / (1024 * 1024)\n",
        "total_mb = total_communication_bytes / (1024 * 1024)\n",
        "\n",
        "print(\"\\n--- Federated Learning Communication Overhead Estimation ---\")\n",
        "print(f\"Estimated model size: {model_size_mb:.2f} MB\")\n",
        "print(f\"Number of clients: {num_clients}\")\n",
        "print(f\"Number of rounds: {num_rounds}\")\n",
        "print(f\"Estimated uplink communication (total): {uplink_mb:.2f} MB\")\n",
        "print(f\"Estimated downlink communication (total): {downlink_mb:.2f} MB\")\n",
        "print(f\"Estimated total communication: {total_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5533795-aff7-4b1e-a9cc-d1b1a813e33d",
        "id": "to9AIlL-NA12"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Federated Learning Communication Overhead Estimation ---\n",
            "Estimated model size: 99.73 MB\n",
            "Number of clients: 5\n",
            "Number of rounds: 5\n",
            "Estimated uplink communication (total): 2493.37 MB\n",
            "Estimated downlink communication (total): 2493.37 MB\n",
            "Estimated total communication: 4986.73 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the full centralized train dataset\n",
        "central_trainset = CXRDataset(train_df, \"./nih_images/train/\", transform=transform)\n",
        "\n",
        "# Create the full test dataset\n",
        "central_testset = CXRDataset(test_df, \"./nih_images/test/\", transform=transform)\n",
        "\n",
        "# Now, DataLoaders\n",
        "central_train_loader = DataLoader(central_trainset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(central_testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Step 1: Rebuild model\n",
        "global_model = NetNIH().to(DEVICE)\n",
        "\n",
        "# Step 2: Load saved weights\n",
        "global_model_fp = load_weights_into_model(global_model, \"/content/FedAdam-DP - round-5-weights.npz\")\n",
        "\n",
        "# Step 3: Run MIA\n",
        "mia_auc = run_membership_inference_attack(global_model_fp, central_train_loader, test_loader)\n",
        "print(f\"Membership Inference Attack AUC: {mia_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a91143b-162c-47d5-f37e-7b6413d20d15",
        "id": "sV6E69W8NA12"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/FedAdam-DP - round-5-weights.npz into model successfully.\n",
            "[Privacy Risk] Membership Inference Attack AUC: 0.5000\n",
            "Membership Inference Attack AUC: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yja9BHpcNA12"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}